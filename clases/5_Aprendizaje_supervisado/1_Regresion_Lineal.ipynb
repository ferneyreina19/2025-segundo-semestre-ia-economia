{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/LinaMariaCastro/curso-ia-para-economia/blob/main/clases/5_Aprendizaje_supervisado/1_Regresion_Lineal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "pvIFU-3M1tJ1"
      },
      "id": "pvIFU-3M1tJ1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Inteligencia Artificial con Aplicaciones en EconomÃ­a I**\n",
        "\n",
        "- ðŸ‘©â€ðŸ« **Profesora:** [Lina MarÃ­a Castro](https://www.linkedin.com/in/lina-maria-castro)  \n",
        "- ðŸ“§ **Email:** [lmcastroco@gmail.com](mailto:lmcastroco@gmail.com)  \n",
        "- ðŸŽ“ **Universidad:** Universidad Externado de Colombia - Facultad de EconomÃ­a"
      ],
      "metadata": {
        "id": "5iiwfbXCQv5D"
      },
      "id": "5iiwfbXCQv5D"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7Kx2M9a1gri"
      },
      "source": [
        "# ðŸ“ˆ **RegresiÃ³n Lineal - De la EconometrÃ­a al Machine Learning**"
      ],
      "id": "m7Kx2M9a1gri"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4VItOmL1grn"
      },
      "source": [
        "**Objetivos de Aprendizaje**\n",
        "\n",
        "Al finalizar este notebook, serÃ¡s capaz de:\n",
        "\n",
        "1.  **Diferenciar** entre el objetivo de **inferencia** (propio de la econometrÃ­a clÃ¡sica) y el de **predicciÃ³n** (central en machine learning).\n",
        "2.  **Implementar** la divisiÃ³n de datos en conjuntos de **entrenamiento (train)** y **prueba (test)** como pilar fundamental para la evaluaciÃ³n de modelos.\n",
        "3.  **Entrenar** un modelo de RegresiÃ³n Lineal con `statsmodels` y `scikit-learn`, interpretando los resultados desde ambas perspectivas.\n",
        "4.  **Evaluar** el desempeÃ±o predictivo de un modelo utilizando mÃ©tricas como el Error CuadrÃ¡tico Medio (RMSE) y el R-cuadrado sobre datos no vistos."
      ],
      "id": "B4VItOmL1grn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Inferencia estadÃ­stica:** permite deducir informaciÃ³n sobre una poblaciÃ³n completa basÃ¡ndonos en el anÃ¡lisis de una muestra representativa de la misma. En lugar de analizar cada elemento de la poblaciÃ³n, lo cual puede ser costoso o incluso imposible, la inferencia estadÃ­stica nos permite extraer conclusiones generales con un cierto grado de confianza."
      ],
      "metadata": {
        "id": "HyCOcA_XKEgn"
      },
      "id": "HyCOcA_XKEgn"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMyGU03d1gro"
      },
      "source": [
        "**IntroducciÃ³n**\n",
        "\n",
        "Imaginemos a dos profesionales:\n",
        "\n",
        "* **El Economista Investigador:** Su trabajo es entender el pasado. Quiere saber *por quÃ©* la inflaciÃ³n subiÃ³ en el Ãºltimo aÃ±o. Para ello, construye un modelo economÃ©trico complejo, buscando identificar las **causas** (e.g., el efecto de la tasa de cambio, el precio del petrÃ³leo). Su objetivo es la **inferencia**: quiere interpretar los coeficientes y su significancia estadÃ­stica para explicar un fenÃ³meno.\n",
        "\n",
        "* **El Analista de Datos en un banco:** Su trabajo es anticipar quÃ© puede pasar en el futuro. Necesita un modelo que le diga, con la mayor precisiÃ³n posible, *cuÃ¡l serÃ¡* la inflaciÃ³n de los prÃ³ximos meses para que el banco pueda anticipar movimientos en las tasas de interÃ©s y tomar decisiones. Su objetivo es la **predicciÃ³n**. Puede que su modelo use variables menos \"explicativas\" teÃ³ricamente, pero si predice bien, es un buen modelo. No le importa tanto el valor exacto de un coeficiente, sino el error de su predicciÃ³n.\n",
        "\n",
        "Empezaremos con un modelo clÃ¡sico para *explicar* y luego lo transformaremos en una herramienta para *predecir*, introduciendo el flujo de trabajo fundamental del Machine Learning."
      ],
      "id": "IMyGU03d1gro"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_iOpOaA1grp"
      },
      "source": [
        "## Importar LibrerÃ­as\n",
        "\n",
        "Como siempre, nuestro primer paso es cargar las herramientas que necesitaremos."
      ],
      "id": "p_iOpOaA1grp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYGwC5B31grp"
      },
      "outputs": [],
      "source": [
        "# LibrerÃ­as para manipulaciÃ³n y anÃ¡lisis de datos\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# LibrerÃ­as para visualizaciÃ³n de datos\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# LibrerÃ­as para modelamiento\n",
        "import statsmodels.api as sm  # Para el enfoque economÃ©trico (inferencia)\n",
        "from sklearn.datasets import fetch_california_housing # Dataset\n",
        "from sklearn.model_selection import train_test_split # Para dividir los datos\n",
        "from sklearn.linear_model import LinearRegression # Modelo de ML (predicciÃ³n)\n",
        "from sklearn.metrics import mean_squared_error, r2_score # MÃ©tricas de evaluaciÃ³n\n",
        "\n",
        "# Pruebas de Supuestos\n",
        "from statsmodels.stats.diagnostic import het_breuschpagan, linear_reset\n",
        "from statsmodels.stats.stattools import jarque_bera\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor"
      ],
      "id": "UYGwC5B31grp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mejorar visualizaciÃ³n de dataframes y grÃ¡ficos"
      ],
      "metadata": {
        "id": "jHE2ZLJuEPIe"
      },
      "id": "jHE2ZLJuEPIe"
    },
    {
      "cell_type": "code",
      "source": [
        "# Que muestre todas las columnas\n",
        "pd.options.display.max_columns = None\n",
        "# En los dataframes, mostrar los float con dos decimales\n",
        "pd.options.display.float_format = '{:,.2f}'.format\n",
        "\n",
        "# Configuraciones para una mejor visualizaciÃ³n\n",
        "sns.set(style='whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (10, 6)"
      ],
      "metadata": {
        "id": "72TA8V1fETCm"
      },
      "execution_count": null,
      "outputs": [],
      "id": "72TA8V1fETCm"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvsozHbO1grq"
      },
      "source": [
        "## Carga y ExploraciÃ³n Inicial de los Datos (EDA)"
      ],
      "id": "IvsozHbO1grq"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset: Precios de Vivienda en California**\n",
        "\n",
        "Utilizaremos un dataset clÃ¡sico que busca predecir el valor mediano de las viviendas en diferentes distritos de California, basado en caracterÃ­sticas de dichos distritos.\n",
        "\n",
        "**CaracterÃ­sticas del Conjunto de Datos:**\n",
        "\n",
        "- NÃºmero de Instancias: 20.640\n",
        "\n",
        "- NÃºmero de Atributos: 8 atributos numÃ©ricos predictivos y la variable objetivo\n",
        "\n",
        "- Variable objetivo: es el valor mediano de la vivienda para los distritos de California, expresado en cientos de miles de USD.\n",
        "\n",
        "InformaciÃ³n de los Atributos:\n",
        "- MedInc: ingreso mediano en el grupo de bloques (en decenas de miles de USD)\n",
        "- HouseAge: mediana de la antigÃ¼edad de la vivienda en el grupo de bloques (en aÃ±os).\n",
        "- AveRooms: nÃºmero promedio de habitaciones por hogar\n",
        "- AveBedrms: nÃºmero promedio de dormitorios por hogar\n",
        "- Population: poblaciÃ³n del grupo de bloques\n",
        "- AveOccup: nÃºmero promedio de miembros del hogar\n",
        "- Latitude: latitud del grupo de bloques\n",
        "- Longitude: longitud del grupo de bloques\n",
        "\n",
        "Este conjunto de datos se derivÃ³ del censo de EE. UU. de 1990.\n",
        "\n",
        "Cada fila representa un grupo de bloques censales, el cual es la unidad geogrÃ¡fica mÃ¡s pequeÃ±a para la cual la Oficina del Censo de EE. UU. publica datos de muestra (un grupo de bloques generalmente tiene una poblaciÃ³n de 600 a 3.000 personas).\n",
        "\n",
        "Un hogar es un grupo de personas que residen dentro de una vivienda."
      ],
      "metadata": {
        "id": "afje5Dl5VjCx"
      },
      "id": "afje5Dl5VjCx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-j7Hgkz1grr"
      },
      "outputs": [],
      "source": [
        "# Cargamos el dataset desde sklearn\n",
        "housing_bunch = fetch_california_housing()\n",
        "# print(housing_bunch.DESCR) # Descomentar para leer la descripciÃ³n"
      ],
      "id": "k-j7Hgkz1grr"
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir a DataFrame de Pandas\n",
        "df = pd.DataFrame(housing_bunch.data, columns=housing_bunch.feature_names)\n",
        "df['MedHouseVal'] = housing_bunch.target # AÃ±adimos la variable objetivo\n",
        "df.head()"
      ],
      "metadata": {
        "id": "-AJ1lKsaMIFf"
      },
      "id": "-AJ1lKsaMIFf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "2qSLwoXBMPZE"
      },
      "id": "2qSLwoXBMPZE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VD1K5ygl1grr"
      },
      "outputs": [],
      "source": [
        "print(\"\\nEstadÃ­sticas descriptivas:\")\n",
        "df.describe()"
      ],
      "id": "VD1K5ygl1grr"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YumVvJC1grs"
      },
      "source": [
        "### VisualizaciÃ³n RÃ¡pida"
      ],
      "id": "9YumVvJC1grs"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos la distribuciÃ³n de nuestra variable objetivo, `MedHouseVal`."
      ],
      "metadata": {
        "id": "GPd_43L3aXJU"
      },
      "id": "GPd_43L3aXJU"
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(df['MedHouseVal'], kde=True)\n",
        "plt.title('DistribuciÃ³n del Valor Mediano de la Vivienda', fontsize=16)\n",
        "plt.xlabel('Valor Mediano de la Vivienda (en cientos de miles de USD)')\n",
        "plt.ylabel('Frecuencia')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9FhQgcHRahsP"
      },
      "id": "9FhQgcHRahsP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tp4E1RMxKlap"
      },
      "source": [
        "**ObservaciÃ³n:** La distribuciÃ³n estÃ¡ **sesgada a la derecha**. Vemos una cola larga de casas caras y una concentraciÃ³n de valores en el extremo superior (~5.0) que indica que los datos fueron \"topeados\" (censurados). Este sesgo es la primera pista de que podrÃ­amos tener problemas de normalidad y heteroscedasticidad."
      ],
      "id": "tp4E1RMxKlap"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Veamos la relaciÃ³n entre el ingreso mediano (`MedInc`), que intuimos es la variable mÃ¡s importante, y el valor mediano de la vivienda (`MedHouseVal`)."
      ],
      "metadata": {
        "id": "gGxwOU6BaeJH"
      },
      "id": "gGxwOU6BaeJH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHy5TAFi1grt"
      },
      "outputs": [],
      "source": [
        "# GrÃ¡fico de dispersiÃ³n para Ingreso vs. Valor de la Vivienda\n",
        "sns.scatterplot(x='MedInc', y='MedHouseVal', data=df, alpha=0.5)\n",
        "plt.title('RelaciÃ³n entre Ingreso Mediano y Valor de la Vivienda', fontsize=16)\n",
        "plt.xlabel('Ingreso Mediano (en decenas de miles de USD)')\n",
        "plt.ylabel('Valor Mediano de la Vivienda (en cientos de miles de USD)')\n",
        "plt.show()"
      ],
      "id": "NHy5TAFi1grt"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Awra2vQV1grt"
      },
      "source": [
        "**ObservaciÃ³n:** Claramente existe una relaciÃ³n lineal positiva, como esperarÃ­amos."
      ],
      "id": "Awra2vQV1grt"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHXAwjq_1gru"
      },
      "source": [
        "## Parte 1: El Enfoque EconomÃ©trico (INFERENCIA)\n",
        "\n",
        "Nuestro objetivo aquÃ­ es **explicar** el precio de la vivienda. Queremos entender la relaciÃ³n entre las variables y cuantificar su significancia estadÃ­stica. Usaremos la librerÃ­a `statsmodels`, que nos da un *output* muy similar al de Stata o R."
      ],
      "id": "QHXAwjq_1gru"
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "tGXVd3myd1wJ"
      },
      "id": "tGXVd3myd1wJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos nuestras variables\n",
        "# X son las variables predictoras (independientes)\n",
        "X = df.drop('MedHouseVal', axis=1)\n",
        "X.head()"
      ],
      "metadata": {
        "id": "HcrgNwySMrn-"
      },
      "id": "HcrgNwySMrn-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y es nuestra variable objetivo (dependiente)\n",
        "y = df['MedHouseVal']\n",
        "y.head()"
      ],
      "metadata": {
        "id": "qtvVjl1FMvpi"
      },
      "id": "qtvVjl1FMvpi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Agregamos la constante (el intercepto)\n",
        "X_con_constante = sm.add_constant(X)\n",
        "X_con_constante.head()"
      ],
      "metadata": {
        "id": "_zXCx-sZM1Uz"
      },
      "id": "_zXCx-sZM1Uz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos y ajustamos el modelo de MÃ­nimos Cuadrados Ordinarios (OLS)\n",
        "modelo_econometrico = sm.OLS(y, X_con_constante).fit()"
      ],
      "metadata": {
        "id": "wbmZuICvM8nm"
      },
      "id": "wbmZuICvM8nm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_HjKT6Q1gru"
      },
      "outputs": [],
      "source": [
        "# Mostramos el resumen completo del modelo\n",
        "print(modelo_econometrico.summary())"
      ],
      "id": "n_HjKT6Q1gru"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWJLcs8O1grv"
      },
      "source": [
        "#### InterpretaciÃ³n EconÃ³mica\n",
        "\n",
        "1.  **R-squared (0.606):** Nuestro modelo **explica** el 60.6% de la variabilidad en el precio de las viviendas.\n",
        "2.  **Coeficientes (coef):**\n",
        "    * **MedInc (0.4367):** Por cada aumento de $10,000 en el ingreso mediano del distrito, el valor mediano de la vivienda aumenta en `0.4367 * $100,000 = $43,670`, *ceteris paribus*.\n",
        "    * **HouseAge (0.0094):** Por cada aÃ±o adicional de antigÃ¼edad promedio de las casas, el valor aumenta en `0.0094 * $100,000 = $940`.\n",
        "3.  **P>|t| (P-values):** Casi todas nuestras variables son **estadÃ­sticamente significativas** (p-valor cercano a cero), lo que nos da confianza en que estas relaciones no son producto del azar.\n",
        "\n",
        "Hasta aquÃ­, hemos hecho un buen trabajo explicando las relaciones *dentro de nuestro dataset*. Pero, Â¿quÃ© tan bueno serÃ­a este modelo para predecir el precio de una casa en un distrito **nuevo**?"
      ],
      "id": "BWJLcs8O1grv"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ld_W2QVS1grv"
      },
      "source": [
        "### DiagnÃ³stico de Supuestos\n",
        "\n",
        "En el machine learning predictivo no se evalÃºa el cumplimiento de los supuestos del modelo de regresiÃ³n lineal con el mismo rigor o propÃ³sito que en la econometrÃ­a.\n",
        "\n",
        "La razÃ³n es la diferencia fundamental en el objetivo de cada disciplina.\n",
        "\n",
        "**El Foco de la EconometrÃ­a: Inferencia**\n",
        "\n",
        "En econometrÃ­a, tu objetivo principal es la inferencia causal o, como mÃ­nimo, la explicaciÃ³n. Quieres entender y cuantificar la relaciÃ³n entre las variables. Las preguntas que buscas responder son del tipo:\n",
        "\n",
        "- Si aumentamos el salario mÃ­nimo en un 1%, Â¿en cuÃ¡nto cambiarÃ¡ el desempleo?Â¿CuÃ¡l es el efecto real de un aÃ±o adicional de educaciÃ³n sobre el salario de una persona, manteniendo todo lo demÃ¡s constante?\n",
        "\n",
        "Para que puedas confiar en que los coeficientes ($\\beta$) de tu regresiÃ³n representan estas relaciones de manera insesgada y eficiente, y para que los p-values y los intervalos de confianza sean vÃ¡lidos, los supuestos del modelo son CRÃTICOS.\n",
        "\n",
        "**El Foco del Machine Learning: PredicciÃ³n**\n",
        "\n",
        "En machine learning, el objetivo principal es la precisiÃ³n predictiva. Tu modelo es una herramienta para hacer la mejor estimaciÃ³n posible sobre datos nuevos y no vistos. La pregunta que buscas responder es:\n",
        "\n",
        "- Con los datos de un nuevo cliente, Â¿cuÃ¡l es la probabilidad de que no pague su crÃ©dito?\n",
        "- Dadas las caracterÃ­sticas de una vivienda, Â¿cuÃ¡l serÃ¡ su precio de venta mÃ¡s probable?\n",
        "\n",
        "En este contexto, la prueba de fuego no es si cumple con los supuestos teÃ³ricos, sino quÃ© tan bien funciona en la prÃ¡ctica. La evaluaciÃ³n se centra en mÃ©tricas de rendimiento sobre un conjunto de prueba (test set), como el Error CuadrÃ¡tico Medio (RMSE) o la PrecisiÃ³n (Accuracy).Si un modelo de regresiÃ³n lineal, a pesar de tener residuos no normales o heterocedasticidad, logra un RMSE mÃ¡s bajo en el test set que otro modelo mÃ¡s complejo, desde una perspectiva puramente predictiva, es el mejor modelo.\n",
        "\n",
        "**Entonces, Â¿los Supuestos no Importan NADA en Machine Learning?**\n",
        "\n",
        "Si bien no son una barrera formal, un buen cientÃ­fico de datos los utiliza como una caja de herramientas de diagnÃ³stico para entender por quÃ© un modelo podrÃ­a no estar funcionando bien y cÃ³mo mejorarlo.\n",
        "\n",
        "Â¿Para quÃ© sirve revisarlos?\n",
        "\n",
        "- **Mejorar el Modelo:** Si tu regresiÃ³n lineal predice mal, revisar los supuestos te puede dar pistas. Por ejemplo, si un grÃ¡fico de residuos vs. valores predichos muestra una curva (violando el supuesto de linealidad), te sugiere que necesitas aÃ±adir tÃ©rminos polinÃ³micos o usar un modelo no lineal (como un Ã¡rbol de decisiÃ³n) para capturar mejor la relaciÃ³n y, por ende, mejorar tu predicciÃ³n.\n",
        "- **IngenierÃ­a de CaracterÃ­sticas (Feature Engineering):** Detectar heterocedasticidad (la varianza del error no es constante) podrÃ­a llevarte a transformar tu variable objetivo (ej. usar $log(Precio)$ en vez de $Precio$), lo cual a menudo estabiliza la varianza y mejora el poder predictivo del modelo.\n",
        "- **Interpretabilidad:** Si ademÃ¡s de predecir quieres tener una idea de la influencia de las variables, entonces los supuestos vuelven a ganar algo de importancia, ya que un modelo que los cumple mejor suele ser mÃ¡s estable y sus coeficientes mÃ¡s fiables.\n"
      ],
      "id": "Ld_W2QVS1grv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a revisar 3 supuestos clave de forma visual y prÃ¡ctica. Primero, calculemos los residuos de nuestro `modelo_economÃ©trico`."
      ],
      "metadata": {
        "id": "2j4scdKCEpOJ"
      },
      "id": "2j4scdKCEpOJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encuentra mayor informaciÃ³n en:\n",
        "- https://www.statsmodels.org/stable/diagnostic.html\n",
        "- https://www.statsmodels.org/dev/examples/notebooks/generated/regression_diagnostics.html"
      ],
      "metadata": {
        "id": "pXhNtgQ_ILtU"
      },
      "id": "pXhNtgQ_ILtU"
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular los valores predichos\n",
        "fitted_values = modelo_econometrico.fittedvalues\n",
        "fitted_values"
      ],
      "metadata": {
        "id": "lE3pISIONyou"
      },
      "id": "lE3pISIONyou",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uSly0Xh1grv"
      },
      "outputs": [],
      "source": [
        "# Calcular los residuos\n",
        "# Residuo = Valor Observado - Valor Predicho\n",
        "residuals = modelo_econometrico.resid\n",
        "residuals"
      ],
      "id": "6uSly0Xh1grv"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFmeur_P1grw"
      },
      "source": [
        "#### Supuesto 1: Homocedasticidad de los Residuos\n",
        "\n",
        "* **Homocedasticidad:** La varianza de los residuos debe ser constante para todos los niveles de las variables predictoras.\n",
        "\n",
        "**Â¿CÃ³mo lo revisamos?** Con un grÃ¡fico de residuos vs. valores predichos.\n",
        "\n",
        "* **Â¿QuÃ© buscamos?** Un patrÃ³n aleatorio de puntos, como una \"nube\" sin forma, centrada en cero.\n",
        "* **Â¿QuÃ© serÃ­a una mala seÃ±al?** Un patrÃ³n discernible, lo que indicarÃ­a problemas de no linealidad o heterocedasticidad (la varianza de los errores no es constante)."
      ],
      "id": "VFmeur_P1grw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDjhSEjA1grw"
      },
      "outputs": [],
      "source": [
        "# GrÃ¡fico de Residuos vs. Valores Ajustados\n",
        "sns.scatterplot(x=fitted_values, y=residuals)\n",
        "plt.axhline(0, color='red', linestyle='--')\n",
        "plt.title('AnÃ¡lisis de Residuos: Residuos vs. Valores Ajustados', fontsize=16)\n",
        "plt.xlabel('Valores Ajustados (Predicciones)')\n",
        "plt.ylabel('Residuos')\n",
        "plt.show()"
      ],
      "id": "RDjhSEjA1grw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvsC8aVd1grx"
      },
      "source": [
        "**InterpretaciÃ³n:**\n",
        "Vemos un patrÃ³n, indicando **heterocedasticidad**."
      ],
      "id": "MvsC8aVd1grx"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "265oGpsL1grx"
      },
      "source": [
        "#### Supuesto 2: Normalidad de los Residuos\n",
        "\n",
        "* **Â¿QuÃ© significa?** Que los residuos del modelo deben seguir una distribuciÃ³n normal.\n",
        "* **Â¿CÃ³mo lo revisamos?** Con un grÃ¡fico Q-Q (Quantile-Quantile) y un histograma. El grÃ¡fico Q-Q compara los cuantiles de nuestros residuos con los de una distribuciÃ³n normal teÃ³rica.\n",
        "\n",
        "* **Â¿QuÃ© buscamos?** En el grÃ¡fico Q-Q, que los puntos se alineen lo mÃ¡s cerca posible a la lÃ­nea diagonal roja. En el histograma, una forma de campana de Gauss."
      ],
      "id": "265oGpsL1grx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RiFH_zQn1grx"
      },
      "outputs": [],
      "source": [
        "# GrÃ¡fico Q-Q\n",
        "sm.qqplot(residuals, line='45', fit=True)\n",
        "plt.title('GrÃ¡fico Q-Q de los Residuos')\n",
        "plt.show()\n",
        "\n",
        "# Histograma de los Residuos\n",
        "sns.histplot(residuals, kde=True)\n",
        "plt.title('DistribuciÃ³n de los Residuos')\n",
        "plt.xlabel('Residuos')\n",
        "plt.show()"
      ],
      "id": "RiFH_zQn1grx"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mopnU4HN1grx"
      },
      "source": [
        "**InterpretaciÃ³n:**\n",
        "Los puntos en el grÃ¡fico Q-Q se desvÃ­an de la lÃ­nea recta en las colas (especialmente en la cola derecha). El histograma tambiÃ©n muestra una \"cola\" mÃ¡s larga hacia la derecha. Esto indica que los residuos **no son perfectamente normales**. Nuestro modelo tiende a subestimar el precio de las casas mÃ¡s caras, generando grandes errores positivos."
      ],
      "id": "mopnU4HN1grx"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- PRUEBAS FORMALES DE DIAGNÃ“STICO ---\")\n",
        "\n",
        "# 1. Test de Normalidad (Jarque-Bera)\n",
        "# H0: Los residuos son normales.\n",
        "name = ['EstadÃ­stico JB', 'p-valor', 'Sesgo', 'Curtosis']\n",
        "jb_test = jarque_bera(modelo_econometrico.resid)\n",
        "print(\"Test de Normalidad (Jarque-Bera):\")\n",
        "print(list(zip(name, jb_test)))\n",
        "\n",
        "# 2. Test de Heteroscedasticidad (Breusch-Pagan)\n",
        "# H0: Los residuos son homocedÃ¡sticos (varianza constante).\n",
        "name = ['EstadÃ­stico LM', 'p-valor LM', 'EstadÃ­stico F', 'p-valor F']\n",
        "bp_test = het_breuschpagan(modelo_econometrico.resid, modelo_econometrico.model.exog)\n",
        "print(\"\\nTest de Heteroscedasticidad (Breusch-Pagan):\")\n",
        "print(list(zip(name, bp_test)))\n",
        "\n",
        "# 3. Test de Linealidad (Ramsey RESET)\n",
        "# H0: El modelo tiene la forma funcional correcta (es lineal).\n",
        "reset_test = linear_reset(modelo_econometrico, power=2, test_type='fitted', use_f=True)\n",
        "print(\"\\nTest de Linealidad (Ramsey RESET):\")\n",
        "print(f\"EstadÃ­stico F: {reset_test.fvalue:.4f}, p-valor: {reset_test.pvalue:.4f}\")"
      ],
      "metadata": {
        "id": "HFxpj_XKhWLr"
      },
      "execution_count": null,
      "outputs": [],
      "id": "HFxpj_XKhWLr"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtWnlyspKlau"
      },
      "source": [
        "**InterpretaciÃ³n de las Pruebas Formales:**\n",
        "\n",
        "* **Normalidad (Jarque-Bera):** El `p-valor` es `0.0`. **Rechazamos** la hipÃ³tesis nula de normalidad.\n",
        "* **Heteroscedasticidad (Breusch-Pagan):** El `p-valor LM` es `0.0`. **Rechazamos** la hipÃ³tesis nula de homocedasticidad.\n",
        "* **Linealidad (Ramsey RESET):** El `p-valor` es `0.0`. **Rechazamos** la hipÃ³tesis nula de que el modelo estÃ¡ especificado correctamente.\n",
        "\n",
        "**ConclusiÃ³n:** Las pruebas formales confirman lo que vimos visualmente. El modelo estÃ¡ **mal especificado** y viola todos los supuestos clave."
      ],
      "id": "CtWnlyspKlau"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9syZzkte1gry"
      },
      "source": [
        "#### Supuesto 3: Ausencia de Multicolinealidad\n",
        "\n",
        "* **Â¿QuÃ© significa?** Que las variables predictoras no deben estar altamente correlacionadas entre sÃ­. Si lo estÃ¡n, el modelo no puede distinguir el efecto individual de cada una.\n",
        "* **Â¿CÃ³mo lo revisamos?** Con una matriz de correlaciÃ³n y el Factor de InflaciÃ³n de la Varianza (VIF). Un VIF > 10 es generalmente considerado una seÃ±al de alerta."
      ],
      "id": "9syZzkte1gry"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjpX7rls1gry"
      },
      "outputs": [],
      "source": [
        "# Calculamos la matriz de correlaciÃ³n\n",
        "corr_matrix = X.corr()\n",
        "\n",
        "# Creamos un mapa de calor para visualizarla\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
        "plt.title('Matriz de CorrelaciÃ³n de las Variables Predictoras')\n",
        "plt.show()"
      ],
      "id": "rjpX7rls1gry"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wgja81Q1gry"
      },
      "source": [
        "**InterpretaciÃ³n:**\n",
        "- Las variables `Latitude` y `Longitude` tienen una correlaciÃ³n negativa considerable (-0.92).\n",
        "- Las variables `AveRooms` y `AveBedrms` tienen una correlaciÃ³n positiva alta de 0.85.\n",
        "\n",
        "* PodrÃ­amos eliminar una de ellas o combinarlas en una nueva variable (reducciÃ³n de dimensionalidad). Esto puede simplificar el modelo y, a veces, mejorar su capacidad de generalizaciÃ³n."
      ],
      "id": "9wgja81Q1gry"
    },
    {
      "cell_type": "code",
      "source": [
        "# FunciÃ³n para calcular el VIF. Nota: Se calcula sobre las variables X, no sobre la constante.\n",
        "def calcular_vif(X_df):\n",
        "    vif_data = pd.DataFrame()\n",
        "    vif_data[\"feature\"] = X_df.columns\n",
        "    vif_data[\"VIF\"] = [variance_inflation_factor(X_df.values, i) for i in range(X_df.shape[1])]\n",
        "    return vif_data.sort_values('VIF', ascending=False)\n",
        "\n",
        "# Calculamos el VIF para nuestras variables X\n",
        "vif_results = calcular_vif(X)\n",
        "print(\"--- Factor de InflaciÃ³n de la Varianza (VIF) ---\")\n",
        "display(vif_results)"
      ],
      "metadata": {
        "id": "4d8qH72EhnZZ"
      },
      "id": "4d8qH72EhnZZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZH_Yxb51gry"
      },
      "source": [
        "## Parte 2: El Enfoque de Machine Learning (PREDICCIÃ“N)\n",
        "\n",
        "Ahora cambiamos de sombrero. Ya no queremos explicar, queremos **predecir**. Para hacerlo, debemos evaluar nuestro modelo en datos que nunca ha visto."
      ],
      "id": "ZZH_Yxb51gry"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSSv8qsH1gry"
      },
      "source": [
        "### Paso clave: Dividir los Datos\n",
        "\n",
        "Imaginen que van a presentar un examen y el profesor les da las preguntas exactas para que estudien. Seguramente sacarÃ¡n una nota perfecta, pero eso no significa que hayan aprendido el tema. Simplemente **memorizaron** las respuestas.\n",
        "\n",
        "Un modelo de machine learning puede hacer lo mismo. Si lo entrenamos y evaluamos con los mismos datos, puede \"memorizar\" las respuestas y parecer perfecto, pero fallarÃ¡ estrepitosamente cuando vea datos nuevos.\n",
        "\n",
        "La soluciÃ³n es simple y poderosa: **dividimos nuestro dataset en dos partes**:\n",
        "* **Conjunto de Entrenamiento (Train set):** La mayorÃ­a de los datos (usualmente 70-80%). Lo usamos para que el modelo aprenda las relaciones.\n",
        "* **Conjunto de Prueba (Test set):** El resto de los datos (20-30%). Lo mantenemos **guardado bajo llave** hasta el final. Lo usaremos para evaluar quÃ© tan bien generaliza el modelo a nuevos datos."
      ],
      "id": "rSSv8qsH1gry"
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Train-Test Split](https://drive.google.com/uc?id=1W8h8fB73KFlKBftFr2phxvAyzbsw8iXx)"
      ],
      "metadata": {
        "id": "1ruxjBszjPWH"
      },
      "id": "1ruxjBszjPWH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8LFOHPy1gry"
      },
      "outputs": [],
      "source": [
        "# Usamos la misma X e y que antes\n",
        "# La funciÃ³n train_test_split hace la magia por nosotros\n",
        "# test_size=0.2 significa que el 20% de los datos serÃ¡n para prueba\n",
        "# random_state asegura que la divisiÃ³n sea siempre la misma, para reproducibilidad\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"TamaÃ±o del dataset original: {X.shape[0]} filas\")\n",
        "print(f\"TamaÃ±o del set de entrenamiento: {X_train.shape[0]} filas\")\n",
        "print(f\"TamaÃ±o del set de prueba: {X_test.shape[0]} filas\")"
      ],
      "id": "X8LFOHPy1gry"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S54RE60l1grz"
      },
      "source": [
        "### Entrenar el Modelo\n",
        "\n",
        "Ahora usaremos `scikit-learn`, la librerÃ­a comunmente utilizada para Machine Learning en Python."
      ],
      "id": "S54RE60l1grz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0h_TSjAE1grz"
      },
      "outputs": [],
      "source": [
        "# 1. Creamos una instancia del modelo\n",
        "modelo_ml = LinearRegression()\n",
        "\n",
        "# 2. Entrenamos el modelo SOLAMENTE con los datos de entrenamiento\n",
        "modelo_ml.fit(X_train, y_train)\n",
        "\n",
        "# 3. Hacemos predicciones sobre el conjunto de prueba (los datos que el modelo nunca ha visto)\n",
        "predicciones = modelo_ml.predict(X_test)"
      ],
      "id": "0h_TSjAE1grz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluar el Modelo"
      ],
      "metadata": {
        "id": "-Nvt87J-Trq2"
      },
      "id": "-Nvt87J-Trq2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### MÃ©tricas de desempeÃ±o del modelo: MSE y RMSE"
      ],
      "metadata": {
        "id": "qGNUVGmaQFtD"
      },
      "id": "qGNUVGmaQFtD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tanto el MSE como el RMSE son mÃ©tricas que cuantifican quÃ© tan \"equivocado\" estÃ¡ nuestro modelo de regresiÃ³n. Ambas miden la distancia promedio entre los valores reales observados y los valores que el modelo predijo.\n",
        "\n",
        "Recuerda que la fÃ³rmula base para cualquier error es:\n",
        "\n",
        "$$e_i = y_i - \\hat{y}_i$$\n",
        "\n",
        "Residuo = Valor Real - Valor Predicho\n",
        "\n",
        "**MSE: Error CuadrÃ¡tico Medio (Mean Squared Error)**\n",
        "\n",
        "El MSE es el punto de partida para evaluar una regresiÃ³n. Su lÃ³gica es:\n",
        "- Calcula cada residuo ($y_i - \\hat{y}_i$).\n",
        "- Eleva cada uno de esos residuos al cuadrado ($e_i^2$).\n",
        "- Calcula el promedio (la media) de todos esos errores al cuadrado.\n",
        "\n",
        "Â¿Por quÃ© elevar al cuadrado?\n",
        "- Penalizar errores grandes: Un error de 10 se convierte en 100, mientras que un error de 2 se convierte en 4. El MSE castiga de forma exponencial al modelo por estar muy equivocado en unas pocas predicciones.\n",
        "- Evitar que los errores se cancelen: Si un modelo se equivoca por +10 en una casa y por -10 en otra, el error promedio simple serÃ­a 0, lo cual es engaÃ±oso. Al elevar al cuadrado, ambos errores (+10 y -10) se convierten en 100, mostrando que el modelo sÃ­ tiene un error significativo.\n",
        "\n",
        "$$MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$$\n",
        "\n",
        "Donde:\n",
        "\n",
        "- $n$: Es el nÃºmero total de observaciones (ej. el nÃºmero de casas en tu set de prueba).\n",
        "- $y_i$: Es el valor real de la observaciÃ³n $i$.\n",
        "- $\\hat{y}_i$: Es el valor predicho por el modelo para la observaciÃ³n $i$.\n",
        "\n",
        "Su principal desventaja es la interpretaciÃ³n. Si estÃ¡s prediciendo precios de casas en dÃ³lares, el MSE te darÃ¡ un error en \"dÃ³lares al cuadrado\". Esto no tiene una intuiciÃ³n de negocio clara.\n",
        "\n",
        "**RMSE: RaÃ­z del Error CuadrÃ¡tico Medio (Root Mean Squared Error)**\n",
        "\n",
        "El RMSE es la soluciÃ³n directa al problema de interpretaciÃ³n del MSE. Es, simple y llanamente, la raÃ­z cuadrada del MSE. Devuelve la mÃ©trica a las unidades originales de la variable. Si tu variable $y$ estÃ¡ en dÃ³lares, tu RMSE tambiÃ©n estarÃ¡ en dÃ³lares.\n",
        "\n",
        "$$RMSE = \\sqrt{MSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}$$\n",
        "\n",
        "El RMSE es la mÃ©trica de error en regresiÃ³n mÃ¡s popular precisamente porque es la mÃ¡s fÃ¡cil de interpretar. Un RMSE de USD 72,000 se traduce directamente a una frase de negocio:\"En promedio, nuestro modelo se equivoca en USD 72,000 al predecir el precio de una vivienda.\" Esta sola frase le permite a un gerente o a un economista entender inmediatamente la precisiÃ³n del modelo y decidir si es lo suficientemente bueno para sus necesidades."
      ],
      "metadata": {
        "id": "I9fJucB6P6wE"
      },
      "id": "I9fJucB6P6wE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ov9ycBmx1grz"
      },
      "outputs": [],
      "source": [
        "# Calculamos las mÃ©tricas de desempeÃ±o\n",
        "mse = mean_squared_error(y_test, predicciones)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, predicciones)\n",
        "\n",
        "print(f\"MÃ©tricas de DesempeÃ±o sobre el Conjunto de Prueba:\")\n",
        "print(f\"-------------------------------------------------\")\n",
        "print(f\"Error CuadrÃ¡tico Medio (MSE): {mse:.4f}\")\n",
        "print(f\"RaÃ­z del Error CuadrÃ¡tico Medio (RMSE): {rmse:.4f}\")\n",
        "print(f\"Coeficiente de DeterminaciÃ³n (R-cuadrado): {r2:.4f}\")"
      ],
      "id": "Ov9ycBmx1grz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hp3fR1U1grz"
      },
      "source": [
        "#### InterpretaciÃ³n\n",
        "\n",
        "1.  **RMSE (Root Mean Squared Error):** Es la mÃ©trica mÃ¡s intuitiva. Nos dice, en promedio, **cuÃ¡nto se equivoca nuestro modelo en las unidades de la variable objetivo**.\n",
        "    * Nuestro modelo, al predecir el valor de una vivienda en un distrito que no ha visto antes, se equivoca en promedio en `0.7456 * $100,000 = $74,560`. Esto nos da una medida tangible y accionable de la precisiÃ³n del modelo.\n",
        "2.  **R-cuadrado (en test):**\n",
        "    * Nuestro modelo es capaz de explicar el 57.58% de la variabilidad en los precios de las viviendas del conjunto de prueba."
      ],
      "id": "_hp3fR1U1grz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### El Pecado de No Dividir"
      ],
      "metadata": {
        "id": "XERP18NGNKz3"
      },
      "id": "XERP18NGNKz3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a ver la diferencia entre los resultados del daset de entrenamiento y el de prueba"
      ],
      "metadata": {
        "id": "LCSl3zZ-URxH"
      },
      "id": "LCSl3zZ-URxH"
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Creamos una instancia del modelo\n",
        "modelo_ml = LinearRegression()\n",
        "\n",
        "# 2. Entrenamos el modelo SOLAMENTE con los datos de entrenamiento\n",
        "modelo_ml.fit(X_train, y_train)\n",
        "\n",
        "# 3. Hacemos predicciones sobre el conjunto de prueba (los datos que el modelo nunca ha visto)\n",
        "predicciones_train = modelo_ml.predict(X_train)\n",
        "predicciones_test = modelo_ml.predict(X_test)"
      ],
      "metadata": {
        "id": "9ldjp0TfK5xE"
      },
      "id": "9ldjp0TfK5xE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculamos las mÃ©tricas de desempeÃ±o para entrenamiento\n",
        "mse_train = mean_squared_error(y_train, predicciones_train)\n",
        "rmse_train = np.sqrt(mse_train)\n",
        "r2_train = r2_score(y_train, predicciones_train)\n",
        "print(f\"MÃ©tricas de DesempeÃ±o sobre el Conjunto de Entranamiento:\")\n",
        "print(f\"-------------------------------------------------\")\n",
        "print(f\"Error CuadrÃ¡tico Medio (MSE): {mse_train:.4f}\")\n",
        "print(f\"RaÃ­z del Error CuadrÃ¡tico Medio (RMSE): {rmse_train:.4f}\")\n",
        "print(f\"Coeficiente de DeterminaciÃ³n (R-cuadrado): {r2_train:.4f}\")"
      ],
      "metadata": {
        "id": "5GgsxIH_LIb4"
      },
      "id": "5GgsxIH_LIb4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculamos las mÃ©tricas de desempeÃ±o para prueba\n",
        "mse_test = mean_squared_error(y_test, predicciones_test)\n",
        "rmse_test = np.sqrt(mse_test)\n",
        "r2_test = r2_score(y_test, predicciones_test)\n",
        "\n",
        "print(f\"MÃ©tricas de DesempeÃ±o sobre el Conjunto de Prueba:\")\n",
        "print(f\"-------------------------------------------------\")\n",
        "print(f\"Error CuadrÃ¡tico Medio (MSE): {mse:.4f}\")\n",
        "print(f\"RaÃ­z del Error CuadrÃ¡tico Medio (RMSE): {rmse:.4f}\")\n",
        "print(f\"Coeficiente de DeterminaciÃ³n (R-cuadrado): {r2:.4f}\")"
      ],
      "metadata": {
        "id": "W0GjnP1EK8mS"
      },
      "id": "W0GjnP1EK8mS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZujLhQP1grz"
      },
      "source": [
        "Ahora vamos a entrenar y evaluar el modelo con **todos** los datos."
      ],
      "id": "EZujLhQP1grz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ColqFaru1gr0"
      },
      "outputs": [],
      "source": [
        "# 1. Entrenamos el modelo con TODOS los datos\n",
        "modelo_tramposo = LinearRegression()\n",
        "modelo_tramposo.fit(X, y) # Usando X e y completas\n",
        "\n",
        "# 2. \"Predecimos\" sobre los mismos datos que usamos para entrenar\n",
        "predicciones_tramposas = modelo_tramposo.predict(X)\n",
        "\n",
        "# 3. Calculamos el R-cuadrado\n",
        "r2_tramposo = r2_score(y, predicciones_tramposas)\n",
        "mse_tramposo = mean_squared_error(y, predicciones_tramposas)\n",
        "rmse_tramposo = np.sqrt(mse_tramposo)\n",
        "\n",
        "print(\"ComparaciÃ³n:\")\n",
        "print(\"--------------------------\")\n",
        "print(f\"R-cuadrado evaluado en test: {r2_test:.4f}\")\n",
        "print(f\"R-cuadrado evaluado en todo el dataset: {r2_tramposo:.4f}\")\n",
        "print(\"--------------------------\")\n",
        "print(f\"RMSE evaluado en test: {rmse_test:.4f}\")\n",
        "print(f\"RMSE evaluado en todo el dataset: {rmse_tramposo:.4f}\")"
      ],
      "id": "ColqFaru1gr0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxOxwTZs1gr0"
      },
      "source": [
        "El R-cuadrado del `modelo_tramposo` es **ligeramente superior** al que obtuvimos de forma honesta. Aunque la diferencia no es masiva en este caso (porque la regresiÃ³n lineal es un modelo simple), en modelos mÃ¡s complejos (como los que veremos mÃ¡s adelante), esta diferencia puede ser abismal (e.g., 0.99 vs 0.65).\n",
        "\n",
        "Esta simple demostraciÃ³n es la justificaciÃ³n mÃ¡s poderosa para **SIEMPRE** dividir tus datos. El desempeÃ±o en el `test set` es la Ãºnica medida real del valor de tu modelo predictivo."
      ],
      "id": "PxOxwTZs1gr0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjskTjAV1gr0"
      },
      "source": [
        "## Conclusiones\n",
        "\n",
        "* La **EconometrÃ­a** (con `statsmodels`) nos ayudÃ³ a **interpretar y explicar** las relaciones entre variables, enfocÃ¡ndonos en la significancia estadÃ­stica.\n",
        "* El **Machine Learning** (con `scikit-learn`) nos introdujo a un nuevo objetivo: **predecir** sobre datos nuevos. Esto nos obligÃ³ a adoptar una nueva prÃ¡ctica: **la divisiÃ³n de datos en entrenamiento y prueba**, y a usar nuevas mÃ©tricas como el **RMSE** para medir el error de predicciÃ³n.\n",
        "\n",
        "El flujo de trabajo que seguimos en la segunda parte (**Cargar -> Explorar -> Dividir -> Entrenar -> Evaluar**) es la base sobre la cual construiremos todo el conocimiento del curso relativo a aprendizaje supervisado."
      ],
      "id": "LjskTjAV1gr0"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}