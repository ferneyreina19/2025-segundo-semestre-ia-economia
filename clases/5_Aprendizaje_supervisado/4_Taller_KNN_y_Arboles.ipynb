{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Taller 4: Optimización de Campañas de Marketing y Variables Clave**\n",
    "\n",
    "### **Contexto del Caso**\n",
    "\n",
    "Un banco portugués lo ha contratado como consultor de ciencia de datos. El banco tiene un problema de eficiencia: sus campañas de telemercadeo para ofrecer depósitos a plazo tienen una tasa de éxito muy baja. Se invierte mucho tiempo y recursos (costos de call center) llamando a clientes que no están interesados.\n",
    "\n",
    "**Su misión:** Construir y optimizar modelos de Machine Learning que predigan qué clientes tienen mayor probabilidad de decir **\"sí\"** a la oferta (`y = 'yes'`). \n",
    "\n",
    "**Entregable Adicional:** El banco no solo quiere un modelo preciso, también quiere entender **POR QUÉ** un cliente es un buen prospecto. Su segundo objetivo es identificar cuáles son las **variables más relevantes** que usan los modelos para tomar sus decisiones. Esto permitirá al banco no solo enfocar sus llamadas, sino también crear mejores guiones de marketing y entender mejor a su clientela.\n",
    "\n",
    "**El Dataset:** `bank-additional-full.csv`. Contiene información de más de 40,000 contactos de telemercadeo, incluyendo datos demográficos del cliente, información socioeconómica (tasa de interés, índice de precios al consumidor) e información de la campaña (último contacto, resultado anterior).\n",
    "\n",
    "**Temas a Cubrir:**\n",
    "1.  Preprocesamiento de datos (Pipelines, ColumnTransformer).\n",
    "2.  `KNeighborsClassifier` + `GridSearchCV`.\n",
    "3.  `DecisionTreeClassifier` + `GridSearchCV`.\n",
    "4.  Análisis de Importancia de Variables (Feature Importance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparación del Entorno y Datos\n",
    "\n",
    "### 1.1. Carga de Librerías\n",
    "\n",
    "Importamos todas las herramientas que necesitaremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulación de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualización\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Modelos y herramientas de Scikit-Learn\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.inspection import permutation_importance # <-- ¡Importante para KNN!\n",
    "\n",
    "# Configuraciones para una mejor visualización\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Carga y Exploración Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2.1: Cargue el dataset desde la siguiente URL.\n",
    "# ¡Cuidado! Este archivo usa punto y coma (;) como separador.\n",
    "url = 'https://raw.githubusercontent.com/Fod-Sol/m-carter-MDS-de/main/Data/bank-additional-full.csv'\n",
    "\n",
    "# ### TU CÓDIGO AQUÍ ###\n",
    "# Usa pd.read_csv() con el argumento sep=';'\n",
    "df = pd.read_csv(url, sep=';')\n",
    "\n",
    "# 1.2.2: Muestre las primeras 5 filas\n",
    "# ### TU CÓDIGO AQUÍ ###\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2.3: Use .info() para revisar los tipos de datos y los nulos\n",
    "# ### TU CÓDIGO AQUÍ ###\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Análisis de `info()`:**\n",
    "* Tenemos 41188 registros.\n",
    "* ¡No hay valores nulos! (Esto es raro y una buena noticia).\n",
    "* Tenemos muchas columnas `object` (categóricas) que deberemos transformar: `job`, `marital`, `education`, etc.\n",
    "* Tenemos varias columnas numéricas (float e int) que deberemos escalar: `age`, `duration`, `campaign`, `euribor3m`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2.4: Revise el balance de la variable objetivo 'y'\n",
    "# Use .value_counts() con normalize=True\n",
    "\n",
    "# ### TU CÓDIGO AQUÍ ###\n",
    "print(\"Distribución de la variable objetivo 'y':\")\n",
    "print(df['y'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Análisis del Target:**\n",
    "El dataset está **muy desbalanceado**. Casi el 89% de los clientes dijeron 'no' y solo el 11% dijo 'yes'.\n",
    "**Implicación Económica:** Esto es normal. Las campañas de marketing tienen bajas tasas de conversión. ¡Por eso es tan importante optimizar! \n",
    "**Implicación Técnica:** El `accuracy` no será una buena métrica. Un modelo que siempre diga 'no' tendrá 89% de accuracy. Deberemos enfocarnos en las métricas de la clase 'yes' (como `recall` y `precision`) dentro del `classification_report`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocesamiento (Usando Pipelines)\n",
    "\n",
    "Vamos a definir nuestro `X` e `y`, y luego crear un `ColumnTransformer` que se encargue de aplicar `StandardScaler` a los números y `OneHotEncoder` a las categorías."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1: Separar X (predictoras) e y (objetivo)\n",
    "\n",
    "# ### TU CÓDIGO AQUÍ ###\n",
    "X = df.drop('y', axis=1)\n",
    "y = df['y']\n",
    "\n",
    "# 2.2: Dividir en train y test (80/20)\n",
    "# ¡Use stratify=y para mantener la proporción de 'yes' y 'no' en ambos sets!\n",
    "\n",
    "# ### TU CÓDIGO AQUÍ ###\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Tamaño Train: {X_train.shape}\")\n",
    "print(f\"Tamaño Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3: Identificar automáticamente las columnas numéricas y categóricas\n",
    "\n",
    "# ### TU CÓDIGO AQUÍ ###\n",
    "numerical_features = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "print(\"Columnas Numéricas:\")\n",
    "print(numerical_features)\n",
    "print(\"\\nColumnas Categóricas:\")\n",
    "print(categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.4: Crear el ColumnTransformer (preprocessor)\n",
    "\n",
    "# Crear los transformadores individuales\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))]) # handle_unknown='ignore' es clave\n",
    "\n",
    "# Unirlos en el preprocesador\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modelo 1: KNN y la Búsqueda del `k` Óptimo\n",
    "\n",
    "Ahora uniremos el preprocesador y el clasificador KNN en un solo `Pipeline` y usaremos `GridSearchCV` para encontrar el mejor `k`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1: Crear el Pipeline completo de KNN\n",
    "# (une el 'preprocessor' con el modelo 'KNeighborsClassifier')\n",
    "\n",
    "# ### TU CÓDIGO AQUÍ ###\n",
    "knn_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# 3.2: Definir la grilla de hiperparámetros para KNN\n",
    "# Queremos probar k = 3, 5, 7, 11 (valores impares para evitar empates)\n",
    "# Pista: El nombre DEBE ser 'model__n_neighbors' (por el nombre en el pipeline)\n",
    "\n",
    "# ### TU CÓDIGO AQUÍ ###\n",
    "param_grid_knn = {\n",
    "    'model__n_neighbors': [3, 5, 7, 11]\n",
    "}\n",
    "\n",
    "# 3.3: Configurar y ejecutar GridSearchCV\n",
    "# Use 3 folds (cv=3) para que corra más rápido.\n",
    "# Use scoring='accuracy' por ahora, aunque sabemos que es desbalanceado.\n",
    "\n",
    "# ### TU CÓDIGO AQUÍ ###\n",
    "grid_knn = GridSearchCV(knn_pipeline, param_grid_knn, cv=3, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "\n",
    "print(\"Iniciando GridSearchCV para KNN...\")\n",
    "grid_knn.fit(X_train, y_train)\n",
    "print(\"GridSearchCV para KNN completado.\")\n",
    "\n",
    "# 3.4: Mostrar los mejores resultados\n",
    "# ### TU CÓDIGO AQUÍ ###\n",
    "print(f\"Mejor valor de 'k' para KNN: {grid_knn.best_params_}\")\n",
    "print(f\"Mejor Accuracy (CV): {grid_knn.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modelo 2: Árbol de Decisión y la Búsqueda del \"Punto Óptimo\"\n",
    "\n",
    "Repetiremos el proceso con un Árbol de Decisión. Esta vez, las \"perillas\" (hiperparámetros) que ajustaremos serán `max_depth` (para evitar sobreajuste) y `min_samples_leaf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1: Crear el Pipeline completo para el Árbol de Decisión\n",
    "# (une el 'preprocessor' con el modelo 'DecisionTreeClassifier')\n",
    "\n",
    "# ### TU CÓDIGO AQUÍ ###\n",
    "tree_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', DecisionTreeClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# 4.2: Definir la grilla de hiperparámetros para el Árbol\n",
    "# Probaremos 'max_depth' = [3, 5, 7]\n",
    "# Y 'min_samples_leaf' = [20, 50, 100] (para controlar la complejidad)\n",
    "\n",
    "# ### TU CÓDIGO AQUÍ ###\n",
    "param_grid_tree = {\n",
    "    'model__max_depth': [3, 5, 7],\n",
    "    'model__min_samples_leaf': [20, 50, 100]\n",
    "}\n",
    "\n",
    "# 4.3: Configurar y ejecutar GridSearchCV\n",
    "# ### TU CÓDIGO AQUÍ ###\n",
    "grid_tree = GridSearchCV(tree_pipeline, param_grid_tree, cv=3, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "\n",
    "print(\"Iniciando GridSearchCV para Árbol de Decisión...\")\n",
    "grid_tree.fit(X_train, y_train)\n",
    "print(\"GridSearchCV para Árbol de Decisión completado.\")\n",
    "\n",
    "# 4.4: Mostrar los mejores resultados\n",
    "# ### TU CÓDIGO AQUÍ ###\n",
    "print(f\"Mejores hiperparámetros para el Árbol: {grid_tree.best_params_}\")\n",
    "print(f\"Mejor Accuracy (CV): {grid_tree.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluación Final y Recomendación de Modelo\n",
    "\n",
    "El Árbol de Decisión probablemente dio un mejor `accuracy` (y es más rápido e interpretable). Vamos a declararlo nuestro **modelo ganador** y evaluarlo en el `test set` (nuestro examen final imparcial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1: Obtener el mejor modelo de árbol (el 'best_estimator_')\n",
    "\n",
    "# ### TU CÓDIGO AQUÍ ###\n",
    "best_tree_model = grid_tree.best_estimator_\n",
    "\n",
    "# 5.2: Realizar predicciones sobre el conjunto de PRUEBA (X_test)\n",
    "\n",
    "# ### TU CÓDIGO AQUÍ ###\n",
    "y_pred_tree = best_tree_model.predict(X_test)\n",
    "\n",
    "# 5.3: Imprimir el Reporte de Clasificación\n",
    "print(\"--- Reporte de Clasificación Final (Árbol Optimizado) ---\")\n",
    "\n",
    "# ### TU CÓDIGO AQUÍ ###\n",
    "print(classification_report(y_test, y_pred_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Análisis del Reporte:**\n",
    "* Observe el `accuracy` general (probablemente ~90%).\n",
    "* Ahora mire la fila de `'yes'`: ¿Cuál es el `precision`? ¿Cuál es el `recall`?\n",
    "* **Recall de 'yes'** (Sensibilidad): ¿Qué porcentaje de los clientes que SÍ compraron logramos identificar? (Usualmente lo más importante para el banco, para no perder oportunidades).\n",
    "* **Precision de 'yes'**: De todos los clientes que el modelo *dijo* que comprarían, ¿qué porcentaje realmente lo hizo? (Importante para no gastar llamadas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.4: Visualizar la Matriz de Confusión\n",
    "cm = confusion_matrix(y_test, y_pred_tree, labels=best_tree_model.classes_)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=best_tree_model.classes_,\n",
    "            yticklabels=best_tree_model.classes_)\n",
    "plt.ylabel('Verdadero')\n",
    "plt.xlabel('Predicho')\n",
    "plt.title('Matriz de Confusión - Árbol Optimizado')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ¿Cuáles son las Variables Más Relevantes?\n",
    "\n",
    "Esta es la segunda parte de la solicitud del banco. Necesitamos explicar *por qué* el modelo toma sus decisiones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Importancia de Variables (Árbol de Decisión)\n",
    "\n",
    "Los árboles de decisión calculan esto automáticamente. Miden cuánto reduce la impureza (Gini) cada variable en promedio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1.1: Extraer el modelo de árbol y el preprocesador del pipeline optimizado\n",
    "# (Ya tenemos 'best_tree_model')\n",
    "\n",
    "# ### TU CÓDIGO AQUÍ ###\n",
    "final_tree_model = best_tree_model.named_steps['model']\n",
    "final_preprocessor = best_tree_model.named_steps['preprocessor']\n",
    "\n",
    "# 6.1.2: Obtener los nombres de las características DESPUÉS del OneHotEncoding\n",
    "\n",
    "# ### TU CÓDIGO AQUÍ ###\n",
    "encoded_feature_names = final_preprocessor.named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(categorical_features)\n",
    "all_feature_names = list(numerical_features) + list(encoded_feature_names)\n",
    "\n",
    "# 6.1.3: Obtener las importancias (del 'final_tree_model')\n",
    "\n",
    "# ### TU CÓDIGO AQUÍ ###\n",
    "importances = final_tree_model.feature_importances_\n",
    "\n",
    "# 6.1.4: Crear un DataFrame para visualizarlas\n",
    "tree_importance_df = pd.DataFrame({\n",
    "    'Feature': all_feature_names,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"--- Top 15 Variables (Árbol de Decisión) ---\")\n",
    "display(tree_importance_df.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1.5: Graficar las 15 variables más importantes\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=tree_importance_df.head(15))\n",
    "plt.title('Top 15 Variables Más Importantes (Árbol de Decisión)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Análisis (Árbol):**\n",
    "* Observe las variables que aparecen en el top. \n",
    "* `duration` (duración de la llamada) casi siempre es la #1. **Pregunta Económica:** ¿Es esta variable útil? No podemos saber la duración *antes* de hacer la llamada. Es un gran predictor, pero no es *accionable* para decidir *a quién* llamar. Es más un resultado.\n",
    "* Fíjese en las siguientes: `euribor3m` (indicador económico), `poutcome_success` (si la campaña anterior fue un éxito), `pdays` (días desde el último contacto) y `age` suelen ser importantes. ¡Estas SÍ son accionables!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Importancia de Variables (KNN)\n",
    "\n",
    "KNN no tiene un atributo `.feature_importances_`. Para él, usamos **Importancia por Permutación**. \n",
    "\n",
    "**Idea:** ¿Qué tanto empeora el modelo (cae el `accuracy`) si \"barajamos\" (permutamos) aleatoriamente los valores de una sola variable? Si el modelo empeora mucho, esa variable era muy importante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.2.1: Obtener el mejor modelo KNN\n",
    "best_knn_model = grid_knn.best_estimator_\n",
    "\n",
    "print(\"Calculando Importancia por Permutación para KNN (puede tardar 1-2 minutos)...\")\n",
    "\n",
    "# 6.2.2: Ejecutar permutation_importance\n",
    "# Lo corremos sobre el test set para ver qué variables importan en datos nuevos.\n",
    "\n",
    "# ### TU CÓDIGO AQUÍ ###\n",
    "perm_importance = permutation_importance(\n",
    "    best_knn_model, \n",
    "    X_test, \n",
    "    y_test, \n",
    "    n_repeats=5,       # Repetir 5 veces para un resultado estable\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 6.2.3: Crear un DataFrame con los resultados\n",
    "knn_importance_df = pd.DataFrame({\n",
    "    'Feature': all_feature_names, # Usamos los mismos nombres de antes\n",
    "    'Importance_mean': perm_importance.importances_mean # Caída promedio en accuracy\n",
    "}).sort_values(by='Importance_mean', ascending=False)\n",
    "\n",
    "print(\"--- Top 15 Variables (KNN por Permutación) ---\")\n",
    "display(knn_importance_df.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.2.4: Graficar las 15 variables más importantes\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(x='Importance_mean', y='Feature', data=knn_importance_df.head(15))\n",
    "plt.title('Top 15 Variables Más Importantes (KNN por Permutación)')\n",
    "plt.xlabel('Caída promedio en Accuracy (Importancia)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Análisis (KNN):**\n",
    "Compare este gráfico con el del Árbol de Decisión. \n",
    "* ¿Están de acuerdo? \n",
    "* Es probable que `duration` siga siendo la #1.\n",
    "* ¿Coinciden en las variables #2, #3 y #4? \n",
    "\n",
    "El hecho de que dos modelos fundamentalmente diferentes (uno basado en reglas, otro en distancias) coincidan en las variables más importantes nos da **mucha confianza** para nuestra recomendación al banco."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusión y Recomendación de Negocio\n",
    "\n",
    "Es hora de traducir nuestros hallazgos en una recomendación de negocio clara."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.1: Visualicemos el árbol de decisión final para encontrar reglas\n",
    "# (Usaremos max_depth=3 para que sea legible)\n",
    "small_tree_model = DecisionTreeClassifier(max_depth=3, min_samples_leaf=50, random_state=42)\n",
    "small_tree_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', small_tree_model)\n",
    "])\n",
    "\n",
    "small_tree_pipeline.fit(X_train, y_train)\n",
    "\n",
    "plt.figure(figsize=(25, 12))\n",
    "plot_tree(small_tree_pipeline.named_steps['model'],\n",
    "          feature_names=all_feature_names,\n",
    "          class_names=best_tree_model.classes_,\n",
    "          filled=True,\n",
    "          fontsize=10,\n",
    "          rounded=True)\n",
    "plt.title(\"Árbol de Decisión Simplificado (para Reglas de Negocio)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **7.2: Tarea de Consultoría (Su Turno)**\n",
    "\n",
    "Basado en los gráficos de **importancia de variables** y en la **visualización del árbol**, escriba una recomendación de 1 párrafo para el gerente del banco.\n",
    "\n",
    "**Puntos a incluir:**\n",
    "1.  ¿Qué modelo recomienda usar (Árbol) y por qué (interpretable, buen rendimiento)?\n",
    "2.  **Excluyendo `duration`**, ¿cuáles son las 3 variables más importantes en las que el banco debería fijarse para decidir a quién llamar?\n",
    "3.  Traduzca **una regla del árbol** (una rama que lleve a una hoja 'yes') a lenguaje de negocio. (Ej: \"Si el cliente tuvo éxito en la campaña anterior Y el índice euribor3m es bajo, la probabilidad de que acepte es alta.\")\n",
    "\n",
    "> **### ESCRIBA SU RECOMENDACIÓN AQUÍ ###**\n",
    "> \n",
    "> ...\n",
    "> \n",
    "> ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
