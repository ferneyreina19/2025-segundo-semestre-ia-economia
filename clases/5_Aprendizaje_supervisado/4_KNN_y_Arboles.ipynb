{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/LinaMariaCastro/curso-ia-para-economia/blob/main/clases/5_Aprendizaje_supervisado/4_KNN_y_Arboles.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "DHNQuIqAmvl5"
      },
      "id": "DHNQuIqAmvl5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Inteligencia Artificial con Aplicaciones en Econom√≠a I**\n",
        "\n",
        "- üë©‚Äçüè´ **Profesora:** [Lina Mar√≠a Castro](https://www.linkedin.com/in/lina-maria-castro)  \n",
        "- üìß **Email:** [lmcastroco@gmail.com](mailto:lmcastroco@gmail.com)  \n",
        "- üéì **Universidad:** Universidad Externado de Colombia - Facultad de Econom√≠a"
      ],
      "metadata": {
        "id": "5iiwfbXCQv5D"
      },
      "id": "5iiwfbXCQv5D"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üßë‚Äçü§ù‚ÄçüßëKNN, üå≥ √Årboles de Decisi√≥n y üéõÔ∏è B√∫squeda de Hiperpar√°metros"
      ],
      "metadata": {
        "id": "gVO93C9XD95g"
      },
      "id": "gVO93C9XD95g"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bd-D9hioDYKm"
      },
      "source": [
        "**Objetivos de Aprendizaje**\n",
        "\n",
        "Al finalizar este notebook, los estudiantes ser√°n capaces de:\n",
        "\n",
        "1.  **Entender la intuici√≥n** detr√°s de dos modelos de clasificaci√≥n no param√©tricos: **K-Nearest Neighbors (KNN)** y **√Årboles de Decisi√≥n**.\n",
        "2. **Comprender el concepto de hiperpar√°metro** y la necesidad de optimizarlo.\n",
        "3.  **Aplicar** los conceptos de **Validaci√≥n Cruzada** (como t√©cnica de evaluaci√≥n robusta) y **Grid Search** (como t√©cnica de optimizaci√≥n de hiperpar√°metros).\n",
        "4.  **Extraer y comparar** la importancia de las variables (`feature importance`) de ambos modelos."
      ],
      "id": "Bd-D9hioDYKm"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfQf-_dmTbXJ"
      },
      "source": [
        "**Introducci√≥n**\n",
        "\n",
        "Imaginemos que somos analistas de riesgo en un banco. Nuestra tarea es decidir si aprobamos o no una nueva tarjeta de cr√©dito a un solicitante. ¬øQu√© informaci√≥n usar√≠amos? Probablemente mirar√≠amos su nivel de ingresos, su historial de pagos, su edad, su nivel educativo, etc.\n",
        "\n",
        "Intuitivamente, har√≠amos dos cosas:\n",
        "\n",
        "1.  **Buscar clientes similares:** Comparar√≠amos al nuevo solicitante con clientes que ya tenemos. Si se parece mucho a un grupo de clientes que siempre pagan a tiempo, es probable que √©l tambi√©n sea un buen cliente. Esta es la l√≥gica detr√°s de **KNN**.\n",
        "2.  **Crear reglas de decisi√≥n:** Podr√≠amos establecer una serie de preguntas. Por ejemplo: \"¬øEl solicitante tiene un historial de pagos sin retrasos? **Si es as√≠**, ¬øsu l√≠mite de cr√©dito solicitado es menor a sus ingresos mensuales? **Si es as√≠**, APROBAR\". Este proceso secuencial de preguntas es la base de los **√Årboles de Decisi√≥n**.\n",
        "\n",
        "Pero, ¬øcu√°ntos \"vecinos similares\" debemos considerar? ¬øQu√© tan \"profundas\" o complejas deben ser nuestras reglas? Estas \"perillas\" que ajustamos en nuestros modelos se llaman **hiperpar√°metros**. Elegir el valor correcto para estas perillas es crucial, y para ello usaremos una t√©cnica fundamental: **Grid Search**."
      ],
      "id": "yfQf-_dmTbXJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTANTE:**\n",
        "\n",
        "- KNN y √°rboles de decisi√≥n son modelos no param√©tricos, ya que no asumen ninguna forma funcional (a diferencia de Regresi√≥n Lineal donde se asume una l√≠nea recta). La estructura del modelo es flexible y se adapta completamente a los datos que observa y la complejidad del modelo no es fija, sino que crece a medida que se agregan m√°s datos.\n",
        "\n",
        "- Ambos resuelven tanto problemas de regresi√≥n como de clasificaci√≥n (vamos a ver un ejemplo de regresi√≥n y en el taller van a trabajar un ejemplo de clasificaci√≥n)."
      ],
      "metadata": {
        "id": "QRZ7weAfplI_"
      },
      "id": "QRZ7weAfplI_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-HU0NxXDYKr"
      },
      "source": [
        "## 1. Preparaci√≥n del Entorno y Datos"
      ],
      "id": "l-HU0NxXDYKr"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1. Carga de Librer√≠as\n",
        "\n",
        "Importamos las herramientas necesarias. Noten que usamos las versiones `Regressor` de los modelos y m√©tricas de regresi√≥n."
      ],
      "metadata": {
        "id": "eDNzkZrg_zTV"
      },
      "id": "eDNzkZrg_zTV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wk-OgeppDYKs"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neighbors import KNeighborsRegressor  # <--- Versi√≥n de Regresi√≥n\n",
        "from sklearn.tree import DecisionTreeRegressor, plot_tree # <--- Versi√≥n de Regresi√≥n\n",
        "from sklearn.metrics import mean_squared_error, r2_score # <--- M√©tricas de Regresi√≥n\n",
        "from sklearn.inspection import permutation_importance # <--- Para Feature Importance"
      ],
      "id": "Wk-OgeppDYKs"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mejorar visualizaci√≥n de dataframes y gr√°ficos"
      ],
      "metadata": {
        "id": "jHE2ZLJuEPIe"
      },
      "id": "jHE2ZLJuEPIe"
    },
    {
      "cell_type": "code",
      "source": [
        "# Que muestre todas las columnas\n",
        "pd.options.display.max_columns = None\n",
        "# En los dataframes, mostrar los float con dos decimales\n",
        "pd.options.display.float_format = '{:,.2f}'.format\n",
        "\n",
        "# Configuraciones para una mejor visualizaci√≥n\n",
        "sns.set(style='whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (10, 6)"
      ],
      "metadata": {
        "id": "72TA8V1fETCm"
      },
      "execution_count": null,
      "outputs": [],
      "id": "72TA8V1fETCm"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zW_zm7LoDYKt"
      },
      "source": [
        "### 1.2. Carga y Exploraci√≥n de Datos"
      ],
      "id": "zW_zm7LoDYKt"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XA46SkM4DYKo"
      },
      "source": [
        "**Contexto del Caso: Prediciendo la Demanda de Bicicletas Compartidas**\n",
        "\n",
        "Somos consultores para la ciudad de Se√∫l. El gobierno quiere optimizar el sistema de bicicletas compartidas. Para reubicar las bicicletas eficientemente y planificar el mantenimiento, necesitan un modelo que prediga la **demanda de bicicletas (cu√°ntas se alquilar√°n)** en una hora determinada.\n",
        "\n",
        "Tenemos un dataset con datos hist√≥ricos por hora que incluye:\n",
        "* **Informaci√≥n temporal:** Fecha, Hora.\n",
        "* **Informaci√≥n clim√°tica:** Temperatura, Humedad, Velocidad del Viento, Lluvia, Nieve, etc.\n",
        "* **Contexto del d√≠a:** Si es festivo o un d√≠a laborable.\n",
        "\n",
        "**Nuestro Objetivo:** Predecir la variable `Rented Bike Count` (un n√∫mero continuo). A diferencia de la clase anterior (predecir una categor√≠a s√≠/no), este es un **problema de regresi√≥n**."
      ],
      "id": "XA46SkM4DYKo"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Variables:**\n",
        "\n",
        "- Date: Fecha\n",
        "- Rented Bike Count: N√∫mero de bicicletas alquiladas  --> **Esta es la variable objetivo**\n",
        "- Hour: Hora\n",
        "- Temperature(¬∞C): Temperatura\n",
        "- Humidity(%): Humedad\n",
        "- Wind speed (m/s): Velocidad del viento\n",
        "- Visibility (10m): Visibilidad\n",
        "- Dew point temperature(¬∞C): Temperatura del punto de roc√≠o\n",
        "- Solar Radiation (MJ/m2): Radiaci√≥n solar\n",
        "- Rainfall(mm): Lluvia\n",
        "- Snowfall (cm): Nevada\n",
        "- Seasons: Estaciones\n",
        "- Holiday: D√≠a festivo\n",
        "- Functioning Day: D√≠a con prestaci√≥n del servicio"
      ],
      "metadata": {
        "id": "UItD_3YMGnDO"
      },
      "id": "UItD_3YMGnDO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T79zZZI4DYKt"
      },
      "outputs": [],
      "source": [
        "# Cargamos el dataset. Usamos un link directo para que el notebook sea reproducible.\n",
        "# Este CSV tiene un problema de codificaci√≥n, as√≠ que especificamos encoding='latin1'\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00560/SeoulBikeData.csv\"\n",
        "df = pd.read_csv(url, encoding='latin1')\n",
        "\n",
        "# Vistazo inicial\n",
        "display(df.head())"
      ],
      "id": "T79zZZI4DYKt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGEP1sHtDYKu"
      },
      "outputs": [],
      "source": [
        "# Revisamos la informaci√≥n y tipos de datos\n",
        "df.info()"
      ],
      "id": "XGEP1sHtDYKu"
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "QbxfUCiZJmHA"
      },
      "id": "QbxfUCiZJmHA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Seasons'].value_counts()"
      ],
      "metadata": {
        "id": "vtskwaToJevu"
      },
      "id": "vtskwaToJevu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Holiday'].value_counts()"
      ],
      "metadata": {
        "id": "ugIOxvFVJNrU"
      },
      "id": "ugIOxvFVJNrU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Functioning Day'].value_counts()"
      ],
      "metadata": {
        "id": "4rUTdxrHJTF3"
      },
      "id": "4rUTdxrHJTF3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkK2np8XDYKv"
      },
      "source": [
        "### 1.3. Limpieza y Preparaci√≥n de Variables (Preprocessing)\n",
        "\n",
        "1.  **Convertir la fecha:** La columna `Date` es un `object` (texto). La convertiremos a formato `datetime` para extraer el mes y el d√≠a de la semana.\n",
        "2.  **Manejar Categ√≥ricas:** Las columnas `Seasons`, `Holiday` y `Functioning Day` son categ√≥ricas y `scikit-learn` no las entiende como texto. Usaremos **One-Hot Encoding**.\n",
        "3.  **Definir X e y:** Separar nuestras variables predictoras (X) de nuestra variable objetivo (y)."
      ],
      "id": "FkK2np8XDYKv"
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Convertir la fecha\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%d/%m/%Y')"
      ],
      "metadata": {
        "id": "C8Qn7AjmLVSF"
      },
      "id": "C8Qn7AjmLVSF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Extraer nuevas caracter√≠sticas de la fecha\n",
        "df['Month'] = df['Date'].dt.month\n",
        "df['DayOfWeek'] = df['Date'].dt.dayofweek # 0=Lunes, 6=Domingo\n",
        "df.sample(5)"
      ],
      "metadata": {
        "id": "yVu_VJYRLXwH"
      },
      "id": "yVu_VJYRLXwH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Definir variable objetivo (y) y predictoras (X)\n",
        "y = df['Rented Bike Count']\n",
        "y.head()"
      ],
      "metadata": {
        "id": "5VaH5B7ZMIds"
      },
      "id": "5VaH5B7ZMIds",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjKSoY7zDYKw"
      },
      "outputs": [],
      "source": [
        "# Quitamos la variable objetivo y la fecha original (que ya no necesitamos)\n",
        "X = df.drop(columns=['Rented Bike Count', 'Date'])\n",
        "X.head()"
      ],
      "id": "KjKSoY7zDYKw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "di8ZgTqSDYKx"
      },
      "source": [
        "### 1.4. Definir el `Pipeline` de Preprocesamiento\n",
        "\n",
        "Para manejar correctamente las variables num√©ricas (que deben ser escaladas) y las categ√≥ricas (que deben ser codificadas), usamos un `ColumnTransformer`. Esto asegura que el escalamiento solo se aplique a los n√∫meros y el One-Hot-Encoding solo a las categor√≠as."
      ],
      "id": "di8ZgTqSDYKx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wl-iEJa-DYKx"
      },
      "outputs": [],
      "source": [
        "# Identificar columnas num√©ricas y categ√≥ricas\n",
        "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns.drop('Hour') # Hour es m√°s como una categor√≠a\n",
        "categorical_features = X.select_dtypes(include=['object']).columns.tolist() + ['Hour', 'Month', 'DayOfWeek'] # Tratamos Hora, Mes y D√≠a como categ√≥ricas\n",
        "\n",
        "print(f\"Columnas Num√©ricas ({len(numerical_features)}): {numerical_features.tolist()}\")\n",
        "print(f\"Columnas Categ√≥ricas ({len(categorical_features)}): {categorical_features}\")\n",
        "\n",
        "# Crear transformadores\n",
        "# 1. Para variables num√©ricas: Estandarizar (media 0, varianza 1)\n",
        "numeric_transformer = StandardScaler()\n",
        "\n",
        "# 2. Para variables categ√≥ricas: One-Hot Encoding\n",
        "categorical_transformer = OneHotEncoder(handle_unknown='ignore') # Ignora categor√≠as no vistas en el test set\n",
        "\n",
        "# Combinar transformadores con ColumnTransformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])"
      ],
      "id": "Wl-iEJa-DYKx"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaItMdpFDYKy"
      },
      "source": [
        "### 1.5. Divisi√≥n de Datos (Train/Test Split)\n",
        "\n",
        "Separamos nuestros datos en entrenamiento y prueba. Es crucial que hagamos esto *antes* de la validaci√≥n cruzada."
      ],
      "id": "DaItMdpFDYKy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2N5LQe8DYKy"
      },
      "outputs": [],
      "source": [
        "# Dividir en entrenamiento (80%) y prueba (20%)\n",
        "# En regresi√≥n, 'stratify' no se usa. Usamos random_state para reproducibilidad.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Tama√±o del conjunto de entrenamiento: {X_train.shape}\")\n",
        "print(f\"Tama√±o del conjunto de prueba: {X_test.shape}\")"
      ],
      "id": "P2N5LQe8DYKy"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ObDlgWGDYKz"
      },
      "source": [
        "## 2. K-Nearest Neighbors (KNN): \"Los similares se comportan de forma similar\"\n",
        "\n",
        "La idea de KNN es simple: para clasificar un nuevo punto u observaci√≥n, buscamos en los datos de entrenamiento los **'k' puntos m√°s cercanos**. La clasificaci√≥n o el valor de la variable objetivo del nuevo punto ser√° el de la mayor√≠a de sus 'k' vecinos.\n",
        "\n",
        "¬øC√≥mo funciona?\n",
        "\n",
        "1.  Encuentra los `k` puntos m√°s similares en los datos de entrenamiento (basado en las variables predictoras).\n",
        "2.  **Calcula el promedio** de la variable objetivo.\n",
        "3.  Ese promedio es la predicci√≥n.\n"
      ],
      "id": "9ObDlgWGDYKz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Link video explicativo: https://www.youtube.com/watch?v=z3140gOhuVI"
      ],
      "metadata": {
        "id": "h6RQzocgOjUn"
      },
      "id": "h6RQzocgOjUn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTANTE:** KNN se basa en medir distancias, por tanto, es obligatorio estandarizar o normalizar las variables predictoras o independientes.\n",
        "\n"
      ],
      "metadata": {
        "id": "NWMqXnnjBo7n"
      },
      "id": "NWMqXnnjBo7n"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a construir un primer modelo con un valor arbitrario de `k`, por ejemplo, `k=5`."
      ],
      "metadata": {
        "id": "rLBg4ZghFTcE"
      },
      "id": "rLBg4ZghFTcE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BrM5_7obDYKz"
      },
      "outputs": [],
      "source": [
        "# Es crucial usar un `Pipeline` para que el preprocesamiento (escalado y encoding) se aplique correctamente\n",
        "# antes de que el modelo KNN calcule las distancias.\n",
        "\n",
        "# 1. Crear el pipeline completo: (Preprocessor + Modelo)\n",
        "knn_pipeline_base = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('model', KNeighborsRegressor(n_neighbors=5)) # Usamos k=5 como base\n",
        "])\n",
        "\n",
        "# 2. Entrenar el pipeline\n",
        "knn_pipeline_base.fit(X_train, y_train)\n",
        "\n",
        "# 3. Realizar predicciones en Train y Test\n",
        "y_pred_knn_base = knn_pipeline_base.predict(X_test)\n",
        "\n",
        "# 4. Evaluar el rendimiento\n",
        "rmse_knn_base = np.sqrt(mean_squared_error(y_test, y_pred_knn_base))\n",
        "r2_knn_base = r2_score(y_test, y_pred_knn_base)\n",
        "\n",
        "print(\"--- KNN Regressor Base (k=5) ---\")\n",
        "print(f\"RMSE test: {rmse_knn_base:.2f} bicicletas\")\n",
        "print(f\"R-cuadrado test: {r2_knn_base:.4f}\")"
      ],
      "id": "BrM5_7obDYKz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6X8OTq7pDYK0"
      },
      "source": [
        "**Interpretaci√≥n:**\n",
        "* **R-cuadrado (R¬≤):** Nos dice que nuestro modelo base explica aproximadamente el **79%** de la variabilidad en la demanda de bicicletas. Pero... ¬øes `k=5` el valor √≥ptimo? Y, ¬øes 0.79 un valor real o ese valor depende de nuestra divisi√≥n de datos?"
      ],
      "id": "6X8OTq7pDYK0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ge-XEFK7DYK1"
      },
      "source": [
        "## 3. √Årboles de Decisi√≥n\n",
        "\n",
        "Un √°rbol de decisi√≥n aprende una serie de reglas `if/else` para segmentar los datos y hacer una predicci√≥n. Su gran ventaja es que podemos visualizarlo y entender exactamente c√≥mo toma sus decisiones, lo que hace que su mayor fortaleza sea la interpretabilidad.\n",
        "\n",
        "¬øC√≥mo funciona?\n",
        "\n",
        "El objetivo del √°rbol es encontrar la mejor pregunta (una partici√≥n) para dividir un grupo grande y ruidoso en dos nuevos subgrupos que sean lo m√°s homog√©neos (o \"puros\") posible internamente, es decir que los valores dentro del grupo tengan baja varianza.\n",
        "\n",
        "De esta forma, va dividiendo los datos con reglas, hasta que ya no hay m√°s divisiones (se llega a una hoja final).\n",
        "\n",
        "Cuando un nuevo dato llega a una hoja final, la predicci√≥n es el **promedio** de la variable objetivo de todas las observaciones que cayeron en esa misma hoja durante el entrenamiento."
      ],
      "id": "ge-XEFK7DYK1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Link video explicativo: https://www.youtube.com/watch?v=z5rmY-LV7ME"
      ],
      "metadata": {
        "id": "88BN2xeqdL2n"
      },
      "id": "88BN2xeqdL2n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcTsZxnFDYK1"
      },
      "outputs": [],
      "source": [
        "# 1. Crear el pipeline para el √Årbol de Decisi√≥n\n",
        "# No ponemos restricciones (ej. max_depth=None) para ver el sobreajuste\n",
        "tree_pipeline_base = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('model', DecisionTreeRegressor(random_state=42))\n",
        "])\n",
        "\n",
        "# 2. Entrenar el pipeline\n",
        "tree_pipeline_base.fit(X_train, y_train)\n",
        "\n",
        "# 3. Realizar predicciones en el Test set\n",
        "y_pred_tree_base = tree_pipeline_base.predict(X_test)\n",
        "\n",
        "# 4. Evaluar el rendimiento\n",
        "rmse_tree_base = np.sqrt(mean_squared_error(y_test, y_pred_tree_base))\n",
        "r2_tree_base = r2_score(y_test, y_pred_tree_base)\n",
        "\n",
        "print(\"--- Decision Tree Regressor Base (sin podar) ---\")\n",
        "print(f\"RMSE test: {rmse_tree_base:.2f} bicicletas\")\n",
        "print(f\"R-cuadrado test: {r2_tree_base:.4f}\")"
      ],
      "id": "tcTsZxnFDYK1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odYCZoceDYK2"
      },
      "source": [
        "**Interpretaci√≥n:** El R¬≤ es de 0.82. El √°rbol sin podar parece memorizar patrones muy espec√≠ficos (sobreajuste), lo que le da un rendimiento decente en este caso. Pero de nuevo, ¬øtuvimos suerte?\n",
        "\n",
        "Visualicemos sus reglas de negocio."
      ],
      "id": "odYCZoceDYK2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-0NfJzXDYK2"
      },
      "outputs": [],
      "source": [
        "# Visualizar el √°rbol (solo las primeras capas para que sea legible)\n",
        "\n",
        "# Necesitamos los nombres de las caracter√≠sticas DESPU√âS del preprocesamiento\n",
        "# Extraemos los nombres del preprocesador DENTRO del pipeline ya entrenado\n",
        "feature_names = tree_pipeline_base.named_steps['preprocessor'].get_feature_names_out()\n",
        "\n",
        "plt.figure(figsize=(25, 12))\n",
        "plot_tree(\n",
        "    tree_pipeline_base.named_steps['model'], # Extraemos el modelo del pipeline\n",
        "    max_depth=3,\n",
        "    feature_names=feature_names,\n",
        "    filled=True,\n",
        "    fontsize=10,\n",
        "    precision=1, # Decimales para mostrar en 'value'\n",
        "    rounded=True\n",
        ")\n",
        "plt.title(\"Visualizaci√≥n √Årbol de Regresi√≥n (primeras 3 capas)\")\n",
        "plt.show()"
      ],
      "id": "M-0NfJzXDYK2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-wRuoABDYK3"
      },
      "source": [
        "**Actividad Pr√°ctica: Traducir una Regla**\n",
        "\n",
        "Miremos la visualizaci√≥n:\n",
        "* **Nodo Ra√≠z:** La primera divisi√≥n es `num__Temprerature <= -0.1`. Esto pr√°cticamente separa la temperatura en bajo cero y sobre cero.\n",
        "* **Valor (`value`):** Observen que el `value` en cada nodo es el **promedio de `Rented Bike Count`**. El promedio general (en la ra√≠z) es de 704.8 bicicletas.\n",
        "\n",
        "**Regla de Negocio (Rama izquierda):**\n",
        "\n",
        "\"Si la temperatura es menor a -0.1 grados y no es oto√±o y la tempereatura es menor a -0,8 grados y no son las 8 de la ma√±ana, entonces la demanda promedio predicha es de 211 bicicletas.\n",
        "\n",
        "Esto tiene perfecto sentido econ√≥mico: en d√≠as fr√≠os, fuera de las horas pico, la demanda es baja."
      ],
      "id": "i-wRuoABDYK3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvOHA5n9DYK3"
      },
      "source": [
        "## 4. Evaluando la Robustez con Validaci√≥n Cruzada (`cross_val_score`)\n",
        "\n",
        "Hasta ahora, hemos evaluado nuestros modelos en *una sola* divisi√≥n de prueba (el 20% que separamos al inicio). ¬øQu√© pasa si esa divisi√≥n fue particularmente \"f√°cil\" o \"dif√≠cil\" por pura suerte?\n",
        "\n",
        "La **Validaci√≥n Cruzada** resuelve esto. En lugar de una sola divisi√≥n, dividimos nuestro `X_train` en (por ejemplo) 5 \"folds\" (pliegues).\n",
        "\n",
        "El proceso es:\n",
        "1.  Entrenar en los pliegues 1, 2, 3, 4 y probar en el 5.\n",
        "2.  Entrenar en los pliegues 1, 2, 3, 5 y probar en el 4.\n",
        "3.  ...y as√≠ sucesivamente.\n",
        "\n",
        "Al final, obtenemos 5 scores (uno por cada pliegue). El **promedio** de estos scores es una medida mucho m√°s robusta y confiable del rendimiento real del modelo.\n",
        "\n",
        "La herramienta para hacer esto r√°pidamente es `cross_val_score`."
      ],
      "id": "mvOHA5n9DYK3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Validacion_Cruzada](https://drive.google.com/uc?id=1D7-4PHpfdOK3IQ4PIEQqR8WHEafhLO0g)"
      ],
      "metadata": {
        "id": "TPyWsanfslXt"
      },
      "id": "TPyWsanfslXt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mgm6Bn-0DYK4"
      },
      "outputs": [],
      "source": [
        "print(\"--- Iniciando Validaci√≥n Cruzada para KNN Base (k=5) ---\")\n",
        "\n",
        "# 1. Usamos cross_val_score en nuestro pipeline base de KNN\n",
        "# Lo corremos sobre TODOS los datos de ENTRENAMIENTO (X_train, y_train)\n",
        "# cv=5 significa 5 folds\n",
        "# scoring='r2' es nuestra m√©trica de inter√©s\n",
        "knn_cv_scores = cross_val_score(\n",
        "    knn_pipeline_base, # Nuestro modelo base con k=5\n",
        "    X_train,\n",
        "    y_train,\n",
        "    cv=5,\n",
        "    scoring='r2',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "print(f\"Scores de cada fold (KNN): {knn_cv_scores}\")\n",
        "print(f\"R¬≤ Promedio (Robusto): {knn_cv_scores.mean():.4f}\")\n",
        "print(f\"R¬≤ Desv. Est√°ndar: {knn_cv_scores.std():.4f}\")"
      ],
      "id": "Mgm6Bn-0DYK4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVv59yxRDYK4"
      },
      "outputs": [],
      "source": [
        "print(\"--- Iniciando Validaci√≥n Cruzada para √Årbol Base (sin podar) ---\")\n",
        "\n",
        "# 2. Repetimos para nuestro pipeline base de √Årbol de Decisi√≥n\n",
        "tree_cv_scores = cross_val_score(\n",
        "    tree_pipeline_base, # Nuestro modelo base sin podar\n",
        "    X_train,\n",
        "    y_train,\n",
        "    cv=5,\n",
        "    scoring='r2',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "print(f\"Scores de cada fold (√Årbol): {tree_cv_scores}\")\n",
        "print(f\"R¬≤ Promedio (Robusto): {tree_cv_scores.mean():.4f}\")\n",
        "print(f\"R¬≤ Desv. Est√°ndar: {tree_cv_scores.std():.4f}\")"
      ],
      "id": "SVv59yxRDYK4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Recuerda** que cada score se calcul√≥ sobre un subconjunto de validaci√≥n que el modelo no us√≥ para entrenar en esa ronda espec√≠fica, por eso el promedio de estos scores es una medida robusta y confiable del rendimiento del modelo."
      ],
      "metadata": {
        "id": "wgkUS13huvQZ"
      },
      "id": "wgkUS13huvQZ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xT5SJx4gDYK5"
      },
      "source": [
        "**Interpretaci√≥n:**\n",
        "* **KNN (k=5):** El R¬≤ robusto es **0.79**, similar que el que obtuvimos en nuestro `test set` inicial. Esto nos dice que el modelo es estable.\n",
        "* **√Årbol (sin podar):** El R¬≤ robusto es **0.79**. Es m√°s bajo que el 0.82 que obtuvimos en el `test set`. Esto sugiere que el √°rbol sin podar es m√°s \"inestable\" y sensible a c√≥mo se dividen los datos.\n",
        "\n",
        "Ahora que sabemos c√≥mo *evaluar* de forma robusta, podemos pasar a *optimizar*."
      ],
      "id": "xT5SJx4gDYK5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. B√∫squeda de Hiperpar√°metros √ìptimos con B√∫squeda de Grilla (`GridSearchCV`)"
      ],
      "metadata": {
        "id": "xARTgjS4gR7O"
      },
      "id": "xARTgjS4gR7O"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hiperpar√°metro**\n",
        "\n",
        "Es una \"perilla\" o un ajuste de configuraci√≥n que nosotros, como analistas, debemos definir antes de que un modelo de machine learning comience a entrenar.\n",
        "\n",
        "Es una configuraci√≥n externa que controla c√≥mo el modelo va a aprender.\n",
        "\n",
        "Ejemplos:\n",
        "- El valor de k en KNN\n",
        "- La profundidad m√°xima de un √Årbol de Decisi√≥n\n",
        "- La tasa de aprendizaje en una red neuronal\n",
        "\n",
        "**Par√°metro**\n",
        "\n",
        "Es un valor interno que el modelo aprende durante el entrenamiento a partir de los datos.\n",
        "\n",
        "Ejemplos:\n",
        "- Los coeficientes (beta) en una regresi√≥n lineal\n",
        "- Las reglas de divisi√≥n (\"si Temperatura < 10...\") que encuentra un √°rbol."
      ],
      "metadata": {
        "id": "UX-BISlQgMH5"
      },
      "id": "UX-BISlQgMH5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OoPSOzHDYK5"
      },
      "source": [
        "\n",
        "\n",
        "Sabemos que `k=5` o un √°rbol `sin podar` fueron elecciones arbitrarias. ¬øC√≥mo encontramos el mejor `k` o la mejor `max_depth`?\n",
        "\n",
        "Podr√≠amos hacer un `cross_val_score` a mano para `k=3`, luego para `k=5`, `k=7`... y comparar los promedios. Pero esto es tedioso.\n",
        "\n",
        "`GridSearchCV` hace exactamente eso: **automatiza la B√∫squeda en Grilla (Grid Search) usando Validaci√≥n Cruzada (Cross-Validation) como m√©todo de evaluaci√≥n.**\n",
        "\n",
        "Le damos:\n",
        "1.  Un modelo (pipeline).\n",
        "2.  Una \"grilla\" de hiperpar√°metros para probar (ej. `k: [3, 5, 7, 11]`).\n",
        "\n",
        "`GridSearchCV` probar√° *cada* valor de la grilla, le har√° una Validaci√≥n Cruzada (ej. `cv=5`), calcular√° el score promedio, y al final nos dir√° cu√°l hiperpar√°metro tuvo el mejor promedio."
      ],
      "id": "0OoPSOzHDYK5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9zxKb4CDYK6"
      },
      "source": [
        "### 5.1. Encontrando el `k` √ìptimo para KNN Regressor"
      ],
      "id": "c9zxKb4CDYK6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2t7OhsF9DYK6"
      },
      "outputs": [],
      "source": [
        "# 1. Re-creamos el pipeline (esto es buena pr√°ctica)\n",
        "knn_pipe_cv = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('model', KNeighborsRegressor())\n",
        "])\n",
        "\n",
        "# 2. Definir la grilla de hiperpar√°metros a probar\n",
        "# OJO: Usamos 'model__n_neighbors' porque el modelo se llama 'model' dentro del pipeline\n",
        "param_grid_knn = {\n",
        "    'model__n_neighbors': [3, 5, 7, 11, 15] # Probaremos estos valores de k\n",
        "}\n",
        "\n",
        "# 3. Configurar GridSearchCV\n",
        "grid_knn = GridSearchCV(\n",
        "    knn_pipe_cv,\n",
        "    param_grid_knn,\n",
        "    cv=5, # 5 folds de validaci√≥n cruzada\n",
        "    scoring='r2', # M√©trica a optimizar: R-cuadrado\n",
        "    n_jobs=-1, # Usar todos los procesadores\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 4. Ejecutar la b√∫squeda (sobre los datos de ENTRENAMIENTO)\n",
        "print(\"Iniciando GridSearchCV para KNN...\")\n",
        "grid_knn.fit(X_train, y_train)\n",
        "print(\"GridSearchCV para KNN completado.\")\n",
        "\n",
        "# 5. Mostrar los resultados\n",
        "print(f\"\\nMejor hiperpar√°metro 'k': {grid_knn.best_params_}\")\n",
        "print(f\"Mejor score R¬≤ de validaci√≥n cruzada: {grid_knn.best_score_:.4f}\")"
      ],
      "id": "2t7OhsF9DYK6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualicemos los resultados** para entender c√≥mo al cambiar `k` cambia el rendimiento."
      ],
      "metadata": {
        "id": "wzYZf3pD5gCD"
      },
      "id": "wzYZf3pD5gCD"
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraer los resultados de la b√∫squeda\n",
        "results_knn = pd.DataFrame(grid_knn.cv_results_)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(results_knn['param_model__n_neighbors'], results_knn['mean_test_score'], marker='o')\n",
        "plt.title(\"Rendimiento de KNN vs. Valor de 'k'\")\n",
        "plt.xlabel(\"k (N√∫mero de Vecinos)\")\n",
        "plt.ylabel(\"Accuracy Promedio en Validaci√≥n Cruzada\")\n",
        "plt.xticks(np.arange(3, 30, 2))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "THuMK4Ro4xdc"
      },
      "id": "THuMK4Ro4xdc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1JfxaX5DYK6"
      },
      "source": [
        "### 5.2. Encontrando la Profundidad √ìptima para el √Årbol de Decisi√≥n"
      ],
      "id": "V1JfxaX5DYK6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rnnegdw8DYK7"
      },
      "outputs": [],
      "source": [
        "# 1. Re-creamos el pipeline\n",
        "tree_pipe_cv = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('model', DecisionTreeRegressor(random_state=42))\n",
        "])\n",
        "\n",
        "# 2. Definir la grilla de hiperpar√°metros\n",
        "param_grid_tree = {\n",
        "    'model__max_depth': [3, 5, 7, 10, 15],       # Qu√© tan profundo puede crecer\n",
        "    'model__min_samples_leaf': [10, 20, 50, 100] # M√≠nimo de muestras en una hoja\n",
        "}\n",
        "\n",
        "# 3. Configurar GridSearchCV\n",
        "grid_tree = GridSearchCV(\n",
        "    tree_pipe_cv,\n",
        "    param_grid_tree,\n",
        "    cv=5,\n",
        "    scoring='r2',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 4. Ejecutar la b√∫squeda\n",
        "print(\"Iniciando GridSearchCV para √Årbol de Decisi√≥n...\")\n",
        "grid_tree.fit(X_train, y_train)\n",
        "print(\"GridSearchCV para √Årbol de Decisi√≥n completado.\")\n",
        "\n",
        "# 5. Mostrar los resultados\n",
        "print(f\"\\nMejores hiperpar√°metros: {grid_tree.best_params_}\")\n",
        "print(f\"Mejor score R¬≤ de validaci√≥n cruzada: {grid_tree.best_score_:.4f}\")"
      ],
      "id": "Rnnegdw8DYK7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOhNH8EIDYK7"
      },
      "source": [
        "**Interpretaci√≥n de la B√∫squeda:**\n",
        "* **KNN:** El R¬≤ √≥ptimo (alrededor de 0.763) se encontr√≥ con `k=5`. Nuestro `k` base estaba cerca.\n",
        "* **√Årbol:** El R¬≤ √≥ptimo (alrededor de 0.81) se encontr√≥ con `max_depth=10` y `min_samples_leaf=10`. Esto es mucho mejor que el KNN y nos da un modelo \"podado\" que generaliza mejor que el √°rbol sin restricciones."
      ],
      "id": "zOhNH8EIDYK7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nota:** GridSearchCV tiene un costo computacional alto, por lo que no se usa para Big Data. En ese caso se divide el conjunto de datos en 3 partes:\n",
        "- Train Set (ej. 70%): Para entrenar el modelo.\n",
        "- Validation Set (ej. 15%): Para ajustar los hiperpar√°metros.\n",
        "- Test Set (ej. 15%): Para dar el reporte final de rendimiento sobre datos nuevos."
      ],
      "metadata": {
        "id": "sNhfz-4QygfQ"
      },
      "id": "sNhfz-4QygfQ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfzEw_qHDYK7"
      },
      "source": [
        "## 6. Evaluaci√≥n Final y Variables Relevantes\n",
        "\n",
        "### 6.1. Evaluaci√≥n Final en el `Test Set`\n",
        "\n",
        "Ahora usamos nuestros modelos optimizados (los `best_estimator_` de GridSearchCV) para hacer predicciones finales en el `test set`, nuestro set de datos que hemos guardado hasta ahora."
      ],
      "id": "JfzEw_qHDYK7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMNw9QgADYK8"
      },
      "outputs": [],
      "source": [
        "# Obtener los mejores modelos encontrados\n",
        "best_knn_model = grid_knn.best_estimator_\n",
        "best_tree_model = grid_tree.best_estimator_\n",
        "\n",
        "# Predecir en el Test set\n",
        "y_pred_knn_final = best_knn_model.predict(X_test)\n",
        "y_pred_tree_final = best_tree_model.predict(X_test)\n",
        "\n",
        "# Calcular R¬≤ finales\n",
        "r2_knn_final = r2_score(y_test, y_pred_knn_final)\n",
        "r2_tree_final = r2_score(y_test, y_pred_tree_final)\n",
        "\n",
        "print(\"--- Comparaci√≥n de Rendimiento Final (R¬≤) en Test Set ---\")\n",
        "print(f\"R¬≤ KNN Base (k=5) en Test:     {r2_knn_base:.4f}\")\n",
        "print(f\"R¬≤ KNN √ìptimo (k=5) en Test:   {r2_knn_final:.4f}\\n\")\n",
        "\n",
        "print(f\"R¬≤ √Årbol Base (sin podar) en Test:  {r2_tree_base:.4f}\")\n",
        "print(f\"R¬≤ √Årbol √ìptimo (podado) en Test: {r2_tree_final:.4f}\")"
      ],
      "id": "LMNw9QgADYK8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaKdbZmmDYLC"
      },
      "source": [
        "**Conclusi√≥n:** ¬°El √Årbol de Decisi√≥n optimizado es nuestro ganador! Con un R¬≤ de **~0.81**, explica el 81% de la variabilidad de la demanda de bicicletas en datos nunca antes vistos. La optimizaci√≥n mejor√≥ su rendimiento significativamente.\n"
      ],
      "id": "zaKdbZmmDYLC"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cmgydauDYLD"
      },
      "source": [
        "### 6.2. ¬øCu√°les son las Variables M√°s Relevantes?\n",
        "\n",
        "Saber qu√© modelo predice mejor es bueno. Saber qu√© variables usa es lo que permite tomar **decisiones de negocio**."
      ],
      "id": "2cmgydauDYLD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Para √Årboles de Decisi√≥n (F√°cil)\n",
        "Los √°rboles calculan la importancia de una variable (`feature_importance_`) midiendo cu√°nto reduce la impureza (o el error, en este caso) cada vez que se usa esa variable para una divisi√≥n. Es un subproducto directo de su entrenamiento."
      ],
      "metadata": {
        "id": "-9Pjc5wH18oU"
      },
      "id": "-9Pjc5wH18oU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9oJFwwPkDYLD"
      },
      "outputs": [],
      "source": [
        "# 1. Extraer el modelo de √°rbol del pipeline\n",
        "tree_model_final = best_tree_model.named_steps['model']\n",
        "\n",
        "# 2. Extraer los nombres de las caracter√≠sticas del preprocesador\n",
        "feature_names = best_tree_model.named_steps['preprocessor'].get_feature_names_out()\n",
        "\n",
        "# 3. Obtener las importancias\n",
        "importances = tree_model_final.feature_importances_\n",
        "\n",
        "# 4. Combinar en un DataFrame y mostrar las 15 m√°s importantes\n",
        "tree_importance_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': importances\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(\"--- Importancia de Variables (√Årbol de Decisi√≥n) ---\")\n",
        "display(tree_importance_df.head(15))\n",
        "\n",
        "# 5. Graficar\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.barplot(x='Importance', y='Feature', data=tree_importance_df.head(15))\n",
        "plt.title('Top 15 Variables M√°s Importantes (√Årbol de Decisi√≥n)')\n",
        "plt.show()"
      ],
      "id": "9oJFwwPkDYLD"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzYSOUP1DYLD"
      },
      "source": [
        "**Interpretaci√≥n Econ√≥mica (√Årbol):**\n",
        "El modelo nos dice que los predictores m√°s potentes de la demanda son:\n",
        "1.  **`num__Temperature(C)`:** La temperatura es, por lejos, el factor m√°s importante.\n",
        "2.  **`num__Humidity(%)`:** La humedad tambi√©n es un factor clave.\n",
        "3.  **`cat__Functioning Day_Yes`:** Si el servicio est√° operativo o no (¬°obvio, pero confirma que el modelo tiene sentido!)\n",
        "4.  **`cat__Hour_18`:** La hora pico de las 6 PM.\n",
        "\n",
        "La administraci√≥n de la ciudad deber√≠a centrar sus modelos de predicci√≥n y operaciones en el **clima** y las **horas pico**."
      ],
      "id": "BzYSOUP1DYLD"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHjni8-tDYLE"
      },
      "source": [
        "#### Para KNN (M√°s Complejo: Usando `Permutation Importance`)\n",
        "\n",
        "KNN no tiene un atributo `.feature_importances_`. Su l√≥gica no se basa en coeficientes o cortes, sino en distancias. La \"importancia\" es impl√≠cita.\n",
        "\n",
        "Para saber qu√© variables le importan a *cualquier* modelo (incluido KNN), usamos la **Importancia por Permutaci√≥n**.\n",
        "\n",
        "**Intuici√≥n:**\n",
        "1.  Calculamos el R¬≤ del modelo en el `test set` (ya lo tenemos: ~0.79).\n",
        "2.  Tomamos *una sola columna* (ej. `Temperatura`) y \"barajamos\" (permutamos) sus valores aleatoriamente, rompiendo su relaci√≥n con la demanda de bicicletas.\n",
        "3.  Volvemos a calcular el R¬≤ con esta columna \"rota\".\n",
        "4.  Si el R¬≤ cae **mucho**, significa que el modelo depend√≠a fuertemente de esa variable. Esa variable es **importante**.\n",
        "5.  Repetimos esto para todas las variables."
      ],
      "id": "DHjni8-tDYLE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "se-taHlJDYLE"
      },
      "outputs": [],
      "source": [
        "print(\"Calculando Importancia por Permutaci√≥n para KNN (puede tardar un momento)...\")\n",
        "\n",
        "# 1. Usamos permutation_importance en el modelo entrenado y el test set\n",
        "# NOTA: Le pasamos el pipeline (best_knn_model) y los datos en crudo (X_test)\n",
        "# El pipeline se encargar√° de preprocesar los datos internamente.\n",
        "perm_importance = permutation_importance(\n",
        "    best_knn_model,\n",
        "    X_test,\n",
        "    y_test,\n",
        "    n_repeats=10,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    scoring='r2'\n",
        ")\n",
        "\n",
        "# 2. Extraer los nombres de las caracter√≠sticas\n",
        "# (Usamos los nombres de las columnas ORIGINALES, ya que permutation_importance\n",
        "# con un pipeline prueba la importancia de las caracter√≠sticas de entrada)\n",
        "feature_names = X_test.columns\n",
        "\n",
        "# 3. Combinar en un DataFrame\n",
        "knn_importance_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance_mean': perm_importance.importances_mean, # Ca√≠da promedio del R¬≤\n",
        "    'Importance_std': perm_importance.importances_std\n",
        "}).sort_values(by='Importance_mean', ascending=False)\n",
        "\n",
        "print(\"\\n--- Importancia de Variables (KNN por Permutaci√≥n) ---\")\n",
        "display(knn_importance_df.head(15))\n",
        "\n",
        "# 4. Graficar\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.barplot(x='Importance_mean', y='Feature', data=knn_importance_df.head(15))\n",
        "plt.title('Top 15 Variables M√°s Importantes (KNN por Permutaci√≥n)')\n",
        "plt.xlabel('Ca√≠da promedio en R¬≤ (Importancia)')\n",
        "plt.show()"
      ],
      "id": "se-taHlJDYLE"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hyBoJBqDYLE"
      },
      "source": [
        "## 7. Conclusiones de la Clase\n",
        "\n",
        "1.  **Modelos Intuitivos para Regresi√≥n:** KNN y los √Årboles de Decisi√≥n se adaptan perfectamente a problemas de regresi√≥n. En lugar de \"votar\" por una clase, **promedian** el valor de sus vecinos (KNN) o de los miembros de su hoja (√Årboles).\n",
        "\n",
        "2.  **CV vs. GridSearch:** Hemos separado dos conceptos clave:\n",
        "    * **Validaci√≥n Cruzada (`cross_val_score`)** es una t√©cnica para *evaluar* robustamente un modelo con hiperpar√°metros fijos (ej. ¬øqu√© tan bueno es mi modelo con k=5?).\n",
        "    * **B√∫squeda de Grilla (`GridSearchCV`)** es una t√©cnica para *optimizar* hiperpar√°metros, que *usa* la validaci√≥n cruzada internamente para comparar cu√°l es el mejor.\n",
        "\n",
        "3.  **Preprocesamiento es Clave:** Vimos c√≥mo un `Pipeline` y un `ColumnTransformer` son esenciales para manejar de forma robusta las variables num√©ricas (escalado) y categ√≥ricas (one-hot encoding), especialmente para modelos sensibles a la distancia como KNN.\n",
        "\n",
        "4.  **Importancia de las Variables:** Aprendimos dos formas de obtenerla:\n",
        "    * **Directa (√Årboles):** Usando el atributo `.feature_importances_`.\n",
        "    * **Agn√≥stica (Para KNN y otros):** Usando `permutation_importance`, que mide el impacto en el rendimiento del modelo al \"romper\" una variable."
      ],
      "id": "1hyBoJBqDYLE"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}